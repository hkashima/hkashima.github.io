<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"> 
<html><head><title>機械学習についての日々の研究</title>
<meta http-equiv="Content-Type" content="text/html; charset=Shift_JIS">
<meta content="MSHTML 6.00.6000.16945" name="GENERATOR">
<meta http-equiv="Content-Style-Type" content="text/css"></head>
<body>
<p><a href="http://www.geocities.jp/kashi_pong/index.html">もどる</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2012.html">2012年の日記</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2011.html">2011年の日記</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2010.html">2010年の日記</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2008.html">2008年の日記</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2007.html">2007年の日記</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2006.html">2006年の日記</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2005.html">2005年の日記</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2004.html">2004年までの日記</a>
</p>
<p><font size="+2"><b>（か）研究日記</b></font></p>
<hr>

<ul>
  <li><a name="20091230"></a>2009/12/30 プライバシ保護データマイニング（Privacy Preserving Data Mining） 
  <ul>
    <li>先日の某集会で使った「差分プライバシー（differential privacy）」の紹介資料を<a href="PPDM_chap16.pdf">おきました</a>。 
    <li>現在、プライバシ保護データマイニングとして研究されている設定には、 
    <ul>
      <li>お互いにデータを隠したまま所望の計算を行う： 
      分散アルゴリズム（グラフのノードが互いに通信しながら計算を行う）を、主に暗号化のテクニックを使ってプライベート化（グラフのノードがもつ情報をお互いに隠したまま計算を行う） 
      する 
      <li>データを匿名化して公開する： 
      データにノイズを加えたり、値をまとめて一般化することで、公開されたデータから個人情報の特定をしにくくする</li></ul>という2つの大きな路線があります（この話題全般の話は「いま日本でPPDMといえば！」の<a href="http://www.fe.dis.titech.ac.jp/member/jun/files/DMSS2008.pdf">佐久間さんの資料</a>や、<a href="http://ibisforest.org/index.php?%E3%83%97%E3%83%A9%E3%82%A4%E3%83%90%E3%82%B7%E3%83%BC%E4%BF%9D%E8%AD%B7%E3%83%87%E3%83%BC%E3%82%BF%E3%83%9E%E3%82%A4%E3%83%8B%E3%83%B3%E3%82%B0">こちら</a>ににまとまっています） 

    <li>一方、差分プライバシーの話で想定しているのは、ユーザがDBに対して問い合わせを行う（ある関数の計算をお願いする）ようなモデルで、DBはデータについての情報をなるべく漏らすことなく、計算をしてあげるのが目的です。 

    <li>これを実現するために、DBからの返答に“ほどほどの”ノイズをいれることで、データについての類推をしにくくしながらも、正しい計算結果を返します。 
    <ul>
      <li>より具体的にはラプラス分布によってノイズを入れます。 
      その幅は、問題ごとに異なり、計算のしやすいものもあれば、そうでないものもあります。</li></ul>
    <li>差分プライバシーは「良く似た別のDBの回答と区別できないならば、（相対的に）安全」であるとする絶妙の（なんか騙されている気がする）概念の導入によって、攻撃者の事前知識などに左右されずにプライバシー強度を（数学的に）議論できるところが関係者にウケているようです。</li></ul>
  <li><a name="20091125"></a>2009/11/25 AUCの直接最適化 
  <ul>
    <li>先日のIBISでも紹介がありましたが、予測問題を扱うときの標準的な評価指標に、AUCと呼ばれる指標がありますが、学習時にこれを直接最適化する手法の（機械学習分野ので）現状が気になって、少し調べてみました。 

    <li>ざっと見た感じだと、このテーマは、機械学習分野では、5年くらいまえにちょっと盛り上がったのち、現在ではなんとなく一段落しているような雰囲気です。 
    しかし、AUCは（先日のIBISで紹介されたように）金融分野でデフォルトの判別モデルの評価指標として定められているAR値(Accuracy 
    Rate)と等価（AR=2*AUC-1の関係により）ため、これを学習の目的関数として直接的に最適化することは（AR値の改善をもたらすかもしれないという意味で）少なくとも金融分野においては、結構重要な応用的価値を持っていると思われます。 

    <ul>
      <li>ちなみに、AUCの定義を再確認しておくと、<br>
<em>AUC = 
      ある正例をランダムとある負例をランダムにとってきたとき、その正例に対するモデルの出力が、その負例に対するモデルの出力よりも大きい確率</em> 
      <br>
つまり、AUCは予測器が正例を負例よりも上にランクすることができる度合いをはかっており、正解率やF指標などと異なり、決定の閾値に依存しない評価指標となっています。 
      </li></ul>
    <li>AUCに限らず、最終的に目標とする指標を直接最適化しようというアプローチは、Vapnikの原理によれば正しい思想であり、信者である僕もだいすき。 

    <li>しかし、いくつか調べた感じだと、すごくうまくいくかというと、必ずしもそうでもない（普通に、正解率や尤度で最適化するのとあまり変わらず、苦労するだけのリターンが得られない）というのが現状のようです。 

    <ul>
      <li>こういう状況は割と他の文脈でも結構現れると思います。 某原理は、必ずしも正しいとはいえないかもしれません。 
      <li>ある論文の実験では、AUCを直接最適化するときには、しないときに比べて（交差検定で決まる）最適な正則化パラメータが大きい、つまり、過学習する傾向があるのかもしれません。</li></ul>
    <li>AUC直接最適化のアプローチとしては、いくつかの論文をみた感じだと、大体2つのアプローチに分けられるようです： 
    <ul>
      <li>(A) 凸な定式化：正例に対する予測値が負例に対する予測値より大きいという制約として入れる。 
      たいていは、予測値の差にマージンをいれてSVMとして定式化する 
      <ul>
        <li>非常に自然な定式化で好き。 何グループかの人たちがほぼ同じ定式化をしています。 この路線での発展版としては、<a href="http://scholar.google.co.jp/scholar?q=A+support+vector+method+for+multivariate+performance+measures++&amp;hl=ja&amp;btnG=%E6%A4%9C%E7%B4%A2&amp;lr=">Joachim氏のSVMperf</a>が、structured 
        outputと同じ枠組みで議論していて、一連の研究の中では一番面白いと思います。</li></ul>
      <li>(B) 非凸な定式化：微分できるようになめらか（微分できないヘビサイド関数を、微分できるシグモイド関数に変更）にして、勾配法で解く 
      <ul>
        <li>こちらの路線は個人的にはあまり好みではないですが、計算効率を考えればありうる選択肢だと思います。 </li></ul></li></ul>
    <li>いずれのアプローチにせよ、計算量の問題が課題として挙げられるでしょう： 
    <ul>
      <li>(1) AUCの定義から、事例数あたるものが（正例数）＋（負例数）ではなくて、（正例数）×（負例数）のオーダーである 
      <li>(2) 
    目的関数の評価が、（正例数）＋（負例数）ではなくて、（正例数）＋（負例数）log（（正例数）＋（負例数））のオーダーである</li></ul>といった問題があります 

    <li>計算量の問題に対処する方法として面白いとおもったのは、<a href="http://win.ua.ac.be/~adrem/bibrem/pubs/CALDERSPKDD07.pdf">計算量に効いてくる正例と負例の絡みをバラすことで、（正例数）＋（負例数）のオーダーにするというもの</a>。 
    この論文では、(B)タイプのアプローチで、ヘビサイド関数を、多項式で近似することで、これを実現しています。 
    <li>個人的には、（A)タイプの制約をパーセプトロンで解くのが、目的関数的にも、速度的にも、一番正しいと思うのですが、どうなんでしょう。</li></ul>
  <li><a name="20091022"></a>2009/10/22 <a href="http://ibis-workshop.org/2009/index.html">IBIS2009</a> 

  <ul>
    <li>実働部隊が若い世代になってから2回目のIBIS。今年は元同僚の<a href="http://www.trl.ibm.com/people/ide/">井手さん</a>が、隊長を務めました。 
    <li>去年はとにかく思いきってシンプルにしたが、今年は、発表は全部<a href="http://ibis-workshop.org/2009/title-poster.html">ポスター</a>だけど、著者が希望する場合には予稿集もありつつ、論文を出したい人にも出したくない人にも対応できるよう2トラック制にしつつと、従来のスタイルとの間を取って、かなり最適解に近いところに落ち着いたかんじ！ 

    <li>今回もいろいろな<a href="http://ibis-workshop.org/2009/invited-talk.html">企画セッション</a>がありました。 
    <ul>
      <li>自分は、<a href="http://www.mi.info.hiroshima-cu.ac.jp/mimura/index_j.html">ミムラ先生</a>と「<a href="http://ibis-workshop.org/2009/invited-talk.html#graph">疎グラフ上のダイナミクス</a>」 
      というセッションを企画させていただいたが、実際かしまは何の役にも立ちませんでした、ごめんなさい。 
      イメージ的には去年の「複雑ネットワークと機械学習」の続編的な感じだけど、内容、かなり物理テク寄りな話。 是非身につけて一発当てたい。 
      <li>個人的には、名前が可愛い<a href="http://ibis-workshop.org/2009/pdf-invited/yoshiba1.pdf">コピュラ</a>がヒット。複数の確率変数間の関係を、同時分布じゃなくて、周辺分布の関数として表す。 
      使われ方としては、思わぬ方向（変数の相関が高い方向）に広がった裾野みたいなのを捉えるためにある、という感じだけど、本質的には、多変数の同時分布をいかに少ないパラメータで表現するかみたいなところなのかなあ、と。&nbsp;いや違うのかもしれないけど。 
      つうか、やっぱみんなノンパラのほうでどうなるのか知りたかったですね。 
      <li>あとは、<a href="http://ibis-workshop.org/2009/invited-talk.html#bakegaku">阿久津先生の埋めこみの話</a>を聴いて、やっぱ埋め込みでカーネル作んないといけない気がしてきたり、<a href="http://ibis-workshop.org/2009/invited-talk.html#oyo">加納先生のやたら熱い講演</a>（とくに基礎研究と応用研究のくだりのあたり）にまったく同感だったり、<a href="http://ibis-workshop.org/2009/pdf-invited/hangli1.pdf">李さんのランキングの話</a>がエライまとまってたりとか。</li></ul>
    <li>発表はいくつかに名前を入れてもらったのだが、僕は売り方に口を出しただけで、テクニカルにはとくに貢献しておりませんよと。</li></ul>
  <li><a name="20090908"></a>2009/09/08 先生、東大に異動してから1ヵ月経過 
  <ul>
    <li>が、基本、大学は夏休みモードだったりで、院試があった以外には、いまのところ何か特別なイベントがあったわけではないのです、先生。 
    <ul>
      <li>いや、ほんとは、研究室合宿があったのだが、先生、事情により参加できず、で、まだ研究室のメンバーとも合流できてない感じ。</li></ul>
    <li>生活のノリとしては、研究＋プロジェクト＋ビジネスだったところが、研究＋教育＋資金獲得にシフトするという感じなのだろうが、まだ空気が読めていない先生。 

    <ul>
      <li>が、先生、近くなったおともだちのところに行ってみたりとか、個室の引きこもり感とか、満喫してます、ふふ。</li></ul>
    <li>先生、赴任が院試直前ということだったので、指導教員候補として僕の名前が出るのはまさに院試のとき、ということで、学生さんにはご指名をいただかないといけないので、<a href="http://www.geocities.jp/kashi_pong/toStudents.html">こんなページ</a>をつくってみたりしたものの、どれほどの効果があったのかは定かではない。 
    ていうか、気づかれてないんじゃねコレ？ 
    <li>あとは、先生、試しに外部資金の申請書を書いて出してみたり。 ちなみに、もうちょっとで科研費の申請らしいので、先生そこが本番。 
    先生、おともだちからの情報集めに精を出す。 
    <li>ところで、<a href="http://www.trl.ibm.com/people/hido/">比戸さん</a>の「Linear-time 
    Graph Kernel」が無事IEEE ICDMに受理された。 
    ちなみに、先生がやったのは、タイトルを考えたくらい。もう1～2本くらいは（他力本願で）通るだろうという算段だったのだが、今回は先生の名前が入ったものはコレ一本。 
    でもまあ、全部しっかりしてるし、またどっかで通るよね先生。 </li></ul>
  <li><a name="20090831"></a>2009/08/31 <a href="http://www.amazon.co.jp/分析力を武器とする企業-強さを支える新しい戦略の科学-トーマス・H・ダベンポート/dp/4822246841/">分析力を武器とする企業</a>（原題：<a href="http://www.amazon.co.jp/Competing-Analytics-New-Science-Winning/dp/1422103323/">Competing 
  on Analytics</a>） 
  <ul>
    <li>ビジネスインテリジェンス（BI）とは、ビジネスにおけるデータ分析技術の利用全般を指す言葉だと思いますが、本書は、BIが企業においてどのような役割を担うか、BIが成功するための要因は何かを、実際にBIを成功させている（ように見える）企業の例とともに示した本です。 

    <ul>
      <li>本書によると「データを組織的かつ系統的に蓄積・分類・検索・分析・加工し、予測や最適化、さらには意思決定に役立てること」ということらしい。 
      <li>なお、モデリングやデータ解析だけではなく、その結果に基づいて意思決定をするときの最適化までを含んでいます。</li></ul>
    <li>話の流れとしては、BIはビジネス業績に結びつくか → Yes 
    という前提にいくつかの事例をもとに納得したあと（そうしないとこの本成立しないからね）、じゃ、そのために何をしたらいいのかということで、BIのロードマップ（何もやってない～データはちょっと集めた 
    → 部分的に利用 → 組織的に利用 → 
    分析力が「武器」）を進めるために、とにもかくにも、経営層の理解と、社運をデータ分析に賭けるくらいのやる気が必要であると説いています。 
    <li>一方、そのようなトップダウンでの導入が望めない場合には、まずは、成果の出やすそうな部分に対して、部分的に分析技術を適用して地道に成果を上げることで、その価値を現場に認めさせるというボトムアップのパスになる、と。 
    そして、その有望な適用先として挙げられるのは、社内を対象にしたものだと、財務、製造、研究開発、人事、社外を対象にしたものだと、サプライヤー（SCM）、顧客（CRM）、ということで、それぞれの事例が紹介されています。 

    <li>また、企業のトップや、分析を専門的に行う人だけではなく、実際、日々の業務において分析を利用する「アマチュア分析者」の重要性を説いています。 
    実際の分析の大部分を行うことになるであろうこの人たちが、正しく、効率よく分析を実施できるように、自動化（その運用ルールの設定も含む）、もしくは、使いやすさを向上させたアマチュア分析者用ツールの整備が重要であると言っています。 

    <li>統計、機械学習、パタン認識、データマイニング、なんでもいいけど、データ解析の技術開発に携わる人間としては、この手の「技術の出口」を押さえておくことは、この世界で生きていくのにそれなりに有意義なこと（というか、ある種の責任）と思います。 

    <li>ところどころ、そんなにうまく行ってるのかよ、というところとか、粒度が全然違う手法が羅列されていたりなど、ん？ 
    と思うところは部分的にはありますが、総じて、真面目にBIの意義を説いていて、データ解析屋気分を盛り上げていくのによい本だと思います。 
    <ul>
      <li>某書の``(data) crunching"（「絶対計算」）という言葉が、どうにもむず痒かった人にも読めるかと。 </li></ul>
    <li>ところで、本書は、今後出てくるべき技術のひとつとして「異常値や、外れ値の検出を行うだけではなく、その原因が何か、ということを追求して解析できる機能」を挙げています。 
    うん、それ、重要だよね、アラートだけ上げられても困るもんね、って …あれ？ そいえば、僕ら以前、それ<a href="http://www.springerlink.com/content/l20340755j1j8760/">やった</a>よね！ 
    と、手前味噌に結び付けたところで、では、このへんで。<a name="20090812"></a></li></ul>
  <li><a name="20090812"></a>2009/08/12 そして10年越しの呪い、解ける 
  <ul>
    <li>複数生物種のネットワークを同時に推定する話 「Simultaneous Inference of Biological Networks 
    （ながいので中略）: A Semi-supervised Approach」 が bioinformatics誌に受理されました。 
    <ul>
      <li>従来： 各生物種のネットワークを、それぞれの種における発現量の類似度をもとに、それぞれの種のネットワークを別々に予測する。 
      <li>我々： 
      さらに、生物をまたいだ配列の類似度を用いて、別の種の情報を利用して、複数のネットワークを同時に予測することで全体として予測精度を上げますよ。 
      <li>テクニカルには、今年のSDMで発表した、複数種リンクをもつネットワーク予測法のノリで。 </li></ul>
    <li>これまで、「バイオインフォやってますよ、じぶん」的なことを10年ちかくも言っておきながら、じつは自分が筆頭著者の論文を出せていなかったのが大きくひっかかっていたので、ひじょうに嬉しい。 

    <li>まさに、呪いが解けたかんじ。 晴れやかな気分で卒業できますな。 </li></ul>
  <li><a name="20090809"></a>2009/08/09 所属が変わりました （IBM→東大） 
  <ul>
    <li>何を思ったのか、7月末で10年勤めたIBMを退職し、8月より東大の情報理工学研究科 数理情報学専攻 <a href="http://www.ibis.t.u-tokyo.ac.jp/pub/moin.cgi/%E3%83%95%E3%83%AD%E3%83%B3%E3%83%88%E3%83%9A%E3%83%BC%E3%82%B8">第6研究室</a>に准教授として赴任しました。 

    <ul>
      <li>学部でいうと、<a href="http://www.keisu.t.u-tokyo.ac.jp/">計数工学科</a>っていうところです。 

      <li>んが、月末にちょっとバタバタして、一週間大学にいけてなかったのですが…。 </li></ul>
    <li>研究室は、今年1月にNECから教授として移られた<a href="http://www.ibis.t.u-tokyo.ac.jp/yamanishi/index_j.html">山西先生</a>と、機械学習界の若きエース<a href="http://www.ibis.t.u-tokyo.ac.jp/pub/moin.cgi/Members/RyotaTomioka">冨岡さん</a>が助教です。 
    そんな二人に挟まれて、ひっそりと暮らしたいと思います。 よろしくおねがいします。 </li></ul>
  <li><a name="20090703"></a>2009/07/03 機械学習技術の分類を「分析的データ解析」と「予測的データ解析」にしようぜみたいな話 
  <ul>
    <li>機械学習とはどういうもの？といったときに、標準的な分類として挙げられるのは 「教師付き学習」と「教師なし学習」であると思う。 
    しかし、これは、「定式化」という研究者の立場からの分類であって、「何ができるのか」という、価値の受け手からの分類にはなっていない。 よね。 
    <li>近年における機械学習の立場は、計算機を使ったデータ解析の、いち流派というものに近く、それがもたらす主要な効果は「データ解析に基づく意思決定（の補助もしくは自動化）」である。 
    よね。 
    <li>そこで、その効果を「分析的データ解析」と「予測的データ解析」に分けてみよう。 それぞれ、 
    <ul>
      <li>分析的データ解析： 過去～現在のデータをもとに、データに潜む知見を得る 
      <li>予測的データ解析： 過去～現在のデータをもとに、将来を予測する </li></ul>みたいなかんじ。 
    <li>つまり、分析的データ解析は、手持ちのデータを理解するために（視点が過去～現在）、予測的データ解析は、予測を行うために（視点が未来）使う。 
    データの中でなにが起こっている(いた）のか、これから何が起こるのか、という視点のちがい。 
    <ul>
      <li>状態空間モデルの予測におけるフィルタリング／平滑化と予測の違いのノリに近いかも。 </li></ul>
    <li>前者の技としては、クラスタリング、異常検知、パターン発見などの教師なし手法が、後者の技としては、分類、回帰、時系列予測などの教師付き手法が大まかに対応するような感じなんだけど、そうではなくて、ある技が前者か後者のどちらかに属するというよりも、その目的によって前者なのか後者なのかが決まる。 
    と。 
    <li>ところで、この分類は、弊社が世の中に訴えかける資料内で同じような分類をみて、インスパイアされて（ぱくって）きたもの。 
    この分類の正しさはさておき、そういう切り口での分類って、機械学習を売っていくのには必要だよね。 </li></ul>
  <li><a name="20090621"></a>2009/06/21 ネットワーク構造情報を用いたエンティティ解決（entity resolution） 
  <ul>
    <li><a href="http://www.cs.utexas.edu/users/ml/riddle/">エンティティ解決</a>とは、実世界で同じものに対応しているデータをまとめるタスク。 

    <ul>
      <li>たとえば、論文の著者で、ある論文の「H.Kashima」という著者は、別の論文の「Hisashi 
      Kashima」と同じかもしれないし、そうではなくて、「Hiroshi Kashima」かもしれない。 これを解決する。 
      <li>日本では、<a href="http://www.dl.kuis.kyoto-u.ac.jp/~oyama/j-index.html">小山さん</a>が以前から取り組んでいる問題。 
      </li></ul>
    <li>この手の問題は「名寄せ」の問題として、至るところに現れる非常に重要な問題。 
    <ul>
      <li>2箇所から、属性のテープルと、クラスラベルのリストをもらっただけでも、簡単につながらなかったりするし。 
      考えてみたら、お仕事ではだいたいいつも出てくるかも。 
      <ul>
        <li>たとえば、プロジェクトデータの分析を行うときに、同じプロジェクトに属する複数のデータを集計してから分析する、など。 </li></ul>
      <li>データベースにおけるスキーママッチングや、自然言語処理における表記のゆれの解消、あとは、連続変数の離散化なども、似て非なるがこれらもまた重要な問題。 
      </li></ul>
    <li>この問題へのアプローチとして、まず、基本となるのは、エンティティ「ペア」の分類問題 
    （著者が「同一人物である」か「同一人物でない」か）として捉える方法。 
    <ul>
      <li>一番簡単なのは、エンティティ同士が（たとえば、本人や論文の名前が）どの程度似ているか、などをベースにクラスタリングする方法。 
      <li>ペアに対して定義される特徴ベクトルの分類 （<a href="http://www.jstage.jst.go.jp/article/tjsai/20/2/105/_pdf/-char/ja/">ペアワイズカーネル</a>）として考えるのも手である。 
      </li></ul>
    <li>ところで、共著関係の場合、共著関係のネットワークがある。 
    このように、エンティティ間のネットワークが与えられている場合には、ネットワーク構造のもつ情報を利用するのも手であろう。 そんなわけで、<a href="http://www.cs.umd.edu/projects/linqs/projects/er/index.html">ゲター先生</a>は、エンティティ情報とネットワーク情報の両方を用いる<a href="http://linqs.cs.umd.edu/basilic/web/Publications/2007/bhattacharya:tkdd07/">collective 
    entity resolution</a>を提唱している。 
    <li>やり方としては、エンティティ同士の類似度を、エンティティ同士の類似度＋関係の類似度（共通の共著者数とか）によって定義して、その類似度を使ってクラスタリングする。 
    そんだけ。 
    <ul>
      <li>読むのメンドウだったら、<a href="http://www.youtube.com/watch?v=zW5BJ7Av-80">これ</a>の前半部分（11分あたりから30分あたり）でその話をしている。 

      <li>彼らはこのほかにも、<a href="http://linqs.cs.umd.edu/basilic/web/Publications/2006/bhattacharya:sdm06/">LDAベースのモデル</a>も提案しているけど、性能は別に変わらんそうだ。 
      </li></ul>
    <li>うん、この問題、まだいろいろと賢くやれそうだよね！ …って思った僕は思う壺な感じ。 
    新しいコンセプトを、一番簡単な方法で実現して、食いつかせる、という、かなり模範的な論文。 こうありたいよね。 
    <li>ところで、神嶌さん曰く「何が同じで、何が違うかを決めるのは認識の本質のような気がします」…っていわれるとなんだかホントにイケてる気がしてくるよ！ 
    </li></ul>
  <li><a name="20090616"></a>2009/06/16 ネットワークの機械学習、3種盛り （続 ICML2009 ひとり読み会） 
  <ul>
    <li>ラベル伝播のグラフをうまく作る「<a href="http://www.cs.mcgill.ca/~icml2009/papers/188.pdf">Graph Construction 
    and b-Matching for Semi-Supervised Learning</a>」（またジェバラ先生） 
    <ul>
      <li>ラベル伝播（label propagation）はネットワーク上での、ノード分類問題を解く手法。 
      <ul>
        <li>「グラフ上で隣同士はラベルが似ている」という制約を使って、既知のラベルをネットワーク上で「伝播」させる。 </li></ul>
      <li>もともと与えられているのが、ネットワークではなく、カーネルなどの類似度（重み付き完全グラフ）や、特徴ベクトルの場合、まず、そこから隣接関係を表すグラフを構成して、それからラベル伝播を適用するのがお作法。 

      <ul>
        <li>もちろん、重み付き完全グラフに対して直接適用してもよいが、スケーラビリティの問題から、それは嫌われる。 
        <ul>
          <li>でも、僕の経験的には、直接適用のほうが予測性能は良かったりなんだけど。 </li></ul></li></ul>
      <li>この論文は、そのグラフの作り方をどうするか、という問題を議論している。 
      <li>結論は、よく使われがちな、k-近傍グラフやε-近傍グラフよりも、b-matchingグラフを使うのがよい、という話。 
      <ul>
        <li>b-matchingグラフとは、各ノードがちょうど次数bを持つようなグラフ （もちろん、枝の類似度重みの総和が最大になるようにする）。 
        <li>b-matchingグラフは、3乗のオーダーくらいの計算量で解けるらしいが、ジェバラ先生たちは、loopy 
        BPベースの速い近似手法を持っている、ということ。 </li></ul></li></ul>
    <li>行列のスペクトル分解を学習してリンク予測する「<a href="http://www.cs.mcgill.ca/~icml2009/papers/281.pdf">Learning Spectral 
    Graph Transformations for Link Prediction</a>」 
    <ul>
      <li>ネットワークの隣接行列 A を埋める代表的な方法として、隣接行列をSVDしたり、(diffusion 
      kernelなどの)グラフカーネルを使う方法がある。 
      <li>これらは、隣接行列 A のスペクトル分解を、A=U<sup>T</sup>ΣU (Uが正規直交、Σが対角)としたとき、一般的に 
      A=U<sup>T</sup>f(Σ)U というように書ける。 
      <li>このf(Σ) （Aの固有値を入力とする1次元の関数）をパラメトライズして学習すると、性能が上がる、という話。 
      <ul>
        <li>隣接行列を A = B + C というように、スペクトル分解用（B）と、f のフィッティング用（C、もしくはB+C）に分け、学習する。 
        </li></ul></li></ul>
    <li>動的なネットワークモデル「<a href="http://www.cs.mcgill.ca/~icml2009/papers/478.pdf">Dynamic Mixed 
    Membership Block Model for Evolving</a>」（シン先生） 
    <ul>
      <li><a href="http://www.cs.princeton.edu/~blei/papers/AiroldiBleiFienbergXing2009.pdf">混合メンバシップモデル（Mixed 
      membership model）</a>は、確率的ブロックモデル（Stochastic Block Model； 
      SBM）の拡張、これに、ダイナミクス（状態空間モデル）を入れたよ 、という話。 
      <li>混合メンバシップモデルは、SBMの潜在変数がリンクごとに切り替わるようなモデル。 
      <ul>
        <li>まず、SBMがどんなモデルだったかというと、、 
        <ul>
          <li>まず、2つのノードをグループ（ノードの種類； 潜在変数）のうちいずれかに所属される。 これらを、一次元だけ1で、残りは0のベクトル 
          <b>x</b><sup>(i)</sup> と <b>x</b><sup>(j)</sup> で表現する。 
          <li>2つのノードの間にリンクが発生する確率は <b>x</b><sup>(i)T</sup> B 
          <b>x</b><sup>(j)</sup> のように表現される。 
          <ul>
            <li>Bの各要素は所属（種類）の間にリンクが発生する確率。 </li></ul>
          <li>しかし、SBMは、一つのノードが一つのグループにしか属さないため、リンク発生のパターンがひととおりしか持つことができない。 
        </li></ul>
        <li>いっぽう、混合メンバシップモデルでは、 
        <ul>
          <li><b>x</b><sup>(i)</sup> と <b>x</b><sup>(j)</sup> 
          を、各成分が0以上で、足すと1になるようなベクトルであるとする。 
          <li><u>リンクをひとつ発生させるごと</u>に、<b>x</b><sup>(i)</sup> と 
          <b>x</b><sup>(j)</sup> をパラメータとしてもつ多項分布を使って、どれか1次元が1で、あとは0であるようなベクトル 
          <b>z</b><sup>(i)</sup> と <b>z</b><sup>(j)</sup> を発生させ、確率 
          <b>z</b><sup>(i)T</sup> B <b>z</b><sup>(j)</sup> によってリンクを生成する。 
          <li>なお、<b>x</b><sup>(i)</sup> などの「各成分が0以上で、足すと1になるようなベクトル」を発生させるために<a href="http://www.cs.cmu.edu/~epxing/papers/aistats2007Final.pdf">ロジスティック正規（logistic 
          normal）分布</a>というのを使っている。 
          <ul>
            <li>Dirichlet分布が扱えない、次元間の相関を入れた、多項分布の生成分布。 
            <li>多次元正規分布によって、次元間に相関のあるベクトルを発生させる（これが潜在変数）。 
            そのあと、「各成分が0以上で、足すと1」にするために、exp(・) かましてから正規化する。 
            <li>計算めんどくさ。 </li></ul>
          <li>リンクごとに、そのリンクに参加するときの役割が、改めてサンプリングされるところがポイント。 
          <ul>
            <li>あるたんぱく質は、このリンクには、この部位を使って作用するが、別のリンクには、別の部位を使って作用するよ、みたいなかんじ。 
            </li></ul></li></ul></li></ul>
      <li>混合メンバシップモデルに、状態空間モデルを入れる。 
      <ul>
        <li>ロジスティック正規（logistic 
        normal）分布の潜在変数（多次元正規分布から出てくるやつ）が状態空間モデルにしたがって遷移する。 </li></ul>
      <li>この手のモデルは、いろいろ出てきてなんだかもういいかなあ、という感じ。</li></ul>
    <li>ええ？ 僕ヒマそう？ ええと…。 </li></ul>
  <li><a name="20090602"></a>2009/06/02 <a href="http://www.cs.mcgill.ca/~icml2009/abstracts.html">ICML2009の論文</a> 
  で面白そうだった2本に目を通す 
  <ul>
    <li>訓練データの順番を考える「<a href="http://www.cs.mcgill.ca/~icml2009/papers/119.pdf">Curriculum 
    Learning</a>」（ベンジオ先生） 
    <ul>
      <li>「カリキュラム学習」という興味を引くタイトル。 この時点で勝ち。 
      <li>経験的に、事例の提示の順番が、学習の効率に影響する。 
      <ul>
        <li>特に、最適化問題として、凸でない場合には、行き先の解も変わってくる </li></ul>
      <li>「学習者に対し、簡単な事例から順に提示するのがよい」という仮説を設け、これをいくつかの実験で検証している。 
      <li>テクニカルにどうこうという話ではないが、コンセプトの勝利。 </li></ul>
    <li>グラフの埋め込み「<a href="http://www.cs.mcgill.ca/~icml2009/papers/418.pdf">Structure Preserving 
    Embedding</a>」（ジェバラ先生） 
    <ul>
      <li>グラフ構造を、ユークリッド空間に「グラフの形を保ちながら」埋め込む話。 
      <ul>
        <li>Figure 4 がかなりイイ感じでアピールしている。 </li></ul>
      <li>標準的な方法としては、隣接行列A（もしくはそのラプラシアン行列）を固有値分解して、埋め込み先を求める。 
      <ul>
        <li>最適化問題としては、argmax<sub>K</sub> Tr(AK) であるような、ランクの低い半正定値行列Kを求める 
</li></ul>
      <li>しかし、埋め込んだ先で、あるノードに対して、枝で接続されているノードが、接続されていないノードよりも近くに埋め込まれているという保証はない。（この論文では、これの性質を「Structure 
      Preserving」と呼んでいる。 
      <li>この制約は、線形制約で表される。 ので、上の目的関数と併せてSDPになる。 
      <li>しかし、SDPじゃないといけないのだろうか。 もうちょっと制約を適当に書けば、固有値問題とかのままでいけると思うのだが 
      （それだとイマイチな結果だった、ということかもしれないけど）。 </li></ul>
    <li>ええ？ 僕ヒマそう？ ええと…。 </li></ul>
  <li><a name="20090601"></a>2009/06/01 賞を受け取りにいったり、引用数の増加を目論んだり 
  <ul>
    <li><a href="http://www.ipsj.or.jp/01kyotsu/award/nagaomakoto/index.html">賞</a>をいただきに、<a href="http://www.ipsj.or.jp/03somu/rijikai_sohkai/sohkai/soukai2009-tujyo53.html">情報処理学会の通常総会</a>というのに行ってきました。 

    <li>同時に受賞されていた、<a href="http://www.aist.go.jp/aist_j/new_research/nr20090427/nr20090427.html">話題</a>の<a href="http://staff.aist.go.jp/m.goto/index-j.html">後藤さん</a>。 実世界インパクトと<a href="http://scholar.google.com/scholar?q=masataka+goto&amp;hl=en&amp;lr=&amp;btnG=Search">アカデミックインパクト</a>を両立されていて、世の中には、スゴイひとがいるもんだなあと。 
    そして「いま、音楽に機械学習はイケるよ！」と教わり、その気になるのだ。 
    <li>スゴイといえば、<a href="http://www.hgc.ims.u-tokyo.ac.jp/~tshibuya/index-j.html">師匠</a>、<a href="http://www.bio5.org/recomb2009/index.php?option=com_content&amp;view=article&amp;id=61&amp;Itemid=90">RECOMBでベストペーパー</a>ですよ。 
    こいつもスゴイ！ 
    <li>ところで、研究の価値の評価軸、いろいろあると思うのだが、間違いなく、そのうちのひとつは引用数（参照数）である。 
    <li>そこで、引用数を増やすためのTipsを…という、よこしまな気持ちで手に取ったのが「<a href="http://www.keisoshobo.co.jp/book/b26521.html">引用する極意 引用される極意</a>」。 
    <li>が、普通に、引用とはなんぞや、引用とはどうあるべきか、という真面目なちゃんとした本でした。 なので、あまり、<a href="http://www.google.com/search?name=f&amp;hl=en&amp;q=%E3%82%AD%E3%83%A0%E6%9C%AC">キム本</a>的なアレはないのですが、あえてひとつ挙げるなら、「引用は、しまくったほうがよい」（自分が引用した論文に釣られて、自分の論文も検索にひっかかるようにするため）くらいかな。 

    <li>ほか、 
    <ul>
      <li>引用（reference、文中で触れられる）と参考文献（bibliography、文中で触れられない）のちがい。 
      <li><a href="http://en.wikipedia.org/wiki/Standing_on_the_shoulders_of_giants">「巨人の肩」はニュートン（オリジナル）のことばではない</a>。 

      <li>引用数が、論文の評価基準になっているのは、理系独特の話らしい。 
      <ul>
        <li>ちなみに、「コンピュータ科学」の平均引用数は、理系のほかの領域として圧倒的に少ないらしい。 
        これは新しい分野だというのもあると思うが、あまり、他人の業績に注意を払わない、という傾向があるのかも。 
    </li></ul></li></ul>とか、（僕が）知らなかった豆知識もいろいろ。 
    <li>で、結局、今後、ジャーナル出版を中心とした専門家同士のピアレビューによる研究評価から、査読なしアーカイブの出現とWebホニャ点ホニャ的な文化によって、オープンな電子媒体における一般大衆による評価にシフトしていくのかもしれないけど、とりあえずは直近の10～20年を生き延びることが目的の我々としては、いままで通りのやり方は続けつつ様子を見るしかないよね的なオチで。 
    </li></ul>
  <li><a name="20090524"></a>2009/05/24 <a href="http://www.siam.org/meetings/sdm09/">SDM2009</a> 
  <ul>
    <li>4月末に、米国で開催された <a href="http://www.siam.org/meetings/sdm09/">SIAM Data 
    Mining Conference</a> に参加してきました。 
    <ul>
      <li>今年も<a href="http://www.siam.org/proceedings/datamining/2009/dm09.php">日本からのアクセプト数は結構な数</a>。 
      が、インフル騒ぎのせいで、日本人の参加者は軒並み参加・発表キャンセル。 結局、日本人参加者は僕と井手さんの2人に。 
      最近、SDMでは日本人の存在感が増していただけに、ちょっと残念。 
      <li>アクセプト率などの統計は<a href="http://www.siam.org/meetings/sdm09/cochair_09.pdf">ここ</a>から見れます。 
      <li>約350件の投稿ちゅう、50件（15％）づつが、オーラルとポスターで受理。 
      <li>会議のノリは、いつも通り。 
      データマイニング系会議としては、もっともこぢんまりした感じで、データマイニング系会議としては、もっとも健全な感じ。 </li></ul>
    <li>ベストペーパーは「<a href="http://www.siam.org/proceedings/datamining/2009/dm09_024_driesa.pdf">Adaptive 
    Concept Drift Detection</a>」、 これはなんと、我々のPAKDD2008の論文「<a href="http://www.trl.ibm.com/people/ide/2008_PAKDD_Hido_et_al.pdf">Unsupervised 
    Change Analysis Using Supervised Learning</a>」をベースにPAC学習風のバウンドやらを導出したもの。 
    ありがとう。 
    <li>招待講演で特筆すべきは、 「<a href="http://manifold.cs.uchicago.edu/manifold_regularization/manifold.html">manifold 
    regularization</a>」の創始者、ニヨギ先生。 こちらは、ひじょうに分かり易い、すばらしい講演だったと思う。 
    <ul>
      <li>僕は相変わらず、連続→離散の流れでラプラシアンが出てくるところがいまひとつ分かってない。 
    </li></ul>もう一件は、ノンパラベイズの大家、ジョーダン先生。 これはまあ、顔見てきました！くらいのかんじで。 
    <li><a href="http://www.siam.org/meetings/sdm09/tutorials.php">チュートリアル</a>は、ラプラシアンモノ（Spectral 
    clustering, Laplacian eigenmap, ...）が幅を利かせてる感じ。 同じようなチュートリアルが2件 （TS2: Data 
    Mining with Graphs and Matrices、 TS4: A Geometric Perspective on 
    Dimensionality Reduction） あった。 
    <li>論文３つ紹介： 
    <ul>
      <li>動的ネットワークのモデル 「<a href="http://www.siam.org/proceedings/datamining/2009/dm09_090_yangt.pdf">A 
      Bayesian Approach Toward Finding Communities and Their Evolutions in 
      Dynamic Social Networks</a>」 
      <ul>
        <li>ネットワークの生成モデルのひとつ Stochastic block model （SBM） に時間変化を導入した。 
        <li>SBMは、<a href="research_diary-2007.html#20070226">以前</a>にも紹介しましたが、 
        <ul>
          <li>各ノードに、隠れ変数（ノードのタイプ）を割り当てる 
          <li>2つの隠れ変数の組み合わせごとに、間にリンクが発生する確率が与えられている </li></ul>というもの 
        <li>これを時間方向に拡張（SBM＋マルコフ過程）したのがこの論文。 
        単位時間ステップに、各ノードのもつノードタイプが別のノードタイプに遷移するとする（マルコフ過程を仮定する）。 
        <li>実験では、ネットワークにおけるコミュニティの時間変化を追うタスクに適用。 
        <li>漸進的だが、あるべき進化ではないかと思う。 </li></ul>
      <li>属性とネットワーク両方使ったクラスタリング 「<a href="http://www.siam.org/proceedings/datamining/2009/dm09_005_wangf.pdf">Integrated 
      KL (K-means - Laplacian) Clustering: A New Clustering Approach by 
      Combining Attribute Data and Pairwise Relations</a>」 
      <ul>
        <li>属性ベースのクラスタリング（k-means）と、グラフベースのクラスタリング（Spectral 
        clustering）を一緒にやる、という話。 
        <li>前者はmaximize<sup><sub>H</sub></sup> H<sup>T</sup>KH みたいな形で、後者は 
        minimize<sup><sub>H</sub></sup> H<sup>T</sup>LH みたいな形で書ける。 
        <li>両方まとめてやろうと思ったときに、これらの線形和で目的関数をつくってもよいが、それだと、ハイパーパラメータが必要になるので、maximize<sup><sub>H</sub></sup> 
        H<sup>T</sup>KH／H<sup>T</sup>LH というように、比にしましょう。 そうすると、一般化固有値問題になる、という話 
        <li>その、「比だとハイパーパラメータ無くなる」という言い分はウソっぽいけど、確かに、ネットワークものにおいては、属性とネットワークの両方の情報がある場合が多いからから、これは使えるかも。 
        </li></ul>
      <li>属性間の関係グラフを使って正則化 「<a href="http://www.siam.org/proceedings/datamining/2009/dm09_035_quanzb.pdf">Aligned 
      Graph Classification with Regularized Logistic Regression</a>」 
      <ul>
        <li>グラフとして与えられた属性間の関係をもとに、パラメータ間の差分について正則化をかける。 
        <li>関係のある属性のパラメータ同士が近くなるように正則化項を入れる。 
        つまり、属性間の関係を表したグラフのラプラシアンをLとしたとき、パラメータ<b>w</b>に対し、<b>w</b><sup>T</sup>L<b>w</b>という正則化を入れる。 

        <li>一発芸だけど、よし。 </li></ul></li></ul>
    <li>んで、そのあと、ワトソン詣での流れ。 おかげさまでGW全潰。 
    <ul>
      <li>今回は、出国直前からなんだか体調悪く、薬ざばざば飲みながら、びくびくしながら、過ごす。 
      <li>んがしかし、今回は、脅威のノーミス移動。 Reno-L.A.-Chicago-N.Y. 
      の国内移動は、航空会社を3つまたいだにも関わらず奇跡のスムーズ接続（荷物もちゃんとあるよ！）。 
      しかも、帰りの日本行き便が（人生初の）ビジネスクラスに。 成田（インフル検疫）でも軽やかに解放、と。 </li></ul></li></ul>
  <li><a name="20090515"></a>2009/05/15 初めての2コマ 
  <ul>
    <li>京大・岩間先生にお声をかけていただき「社会人呼んできて、話をさせる」シリーズみたいな授業で話をさせていただいた。 
    <li>情報学科の4回生全員対象だったらしく、人数多くておののく。 
    <ul>
      <li>学生さんには、こんなんで3時間拘束され、申し訳ない。 が、ちょっと早めに終わったので良しということにしていただきたい。 </li></ul>
    <li>これまでにしゃべった最長時間は90分くらいだったと思うので、2コマは未知の領域。 
    マイクを使えたのでなんとかなったのだが、地声でだったら、絶対最後まで声もってない。 
    <li><a href="http://www.geocities.jp/kashi_pong/publication/Kyoto090515_censored.zip">不誠実ながらも、一通り流してカーネルのところまで持って行って</a>、最後に、<a href="http://www.geocities.jp/kashi_pong/publication/Kyoto090515_2.zip">グラフカーネルどーん</a>、というつもりが、結局前半部分で終了。 
    意外に時間かかるものだ。 
    <ul>
      <li>カーネル和本で習ったリプレゼンター定理、さっそく使わせていただきました。 ありがとうございます。 </li></ul>
    <li>いちおう、弊社の宣伝（最初のほうにTRLの概要パッケージからぱくってきたのをいくつか挿入）はできたような気がするので、ベースラインはキープ、できたような、できてないような。 
    </li></ul>
  <li><a name="20090509"></a>2009/05/09 近況 
  <ul>
    <li>加藤さんの論文が、IEEE Transactions on Knowledge and Data Engineering に受理されました。 
    こいつはスゴイです。 加藤さん最近絶好調です。 ありがとうございます。 
    <ul>
      <li>マルチタスク学習（よく似た複数の学習問題を同時に解く）を扱っています。 
      似ているタスクに対するモデルのパラメータは似ているはず、という制約を入れた学習問題を、SOCP(Second Order Cone 
      Programming)という比較的効率的に解ける最適化問題に落とします。 
      <ul>
        <li><font size="-1">Tsuyoshi Kato, <u>Hisashi Kashima</u>, Masashi 
        Sugiyama and Kiyoshi Asai: Conic Programming for Multi-task Learning, 
        IEEE Transactions on Knowledge and Data Engineering, 2009.</font> 
      </li></ul></li></ul>
    <li>来週、5/15(金)に京大で、2コマの授業をすることになりました。 
    <ul>
      <li>90分×2なので、機械学習の基本的なところから、手前味噌まで、知っているすべてを話します。 でも、余ると思います。 
      <li>準備がまったく進まない。 大学の先生ってエライですね…。 </li></ul></li></ul>
  <li><a name="20090423"></a>2009/04/23 長尾真記念特別賞をいただけることになりました 
  <ul>
    <li>情報処理学会より<a href="http://www.ipsj.or.jp/01kyotsu/award/nagaomakoto/index.html">長尾真記念特別賞</a>をいただけることになりました。 
    ありがとうございます。 
    <li>受賞の対象は、木／グラフのカーネルと、ネットワーク予測の研究をひとまとめにして「構造データ解析のための機械学習手法」の研究という感じ。 
    <li>賞金つきの賞というのは初めていただいた。 論文的な話で、お金がもらえる、というのが、なんだか不思議な感じ。 
    共著の皆様からの頂きものもののおかげなので、なにがしかお返ししないとね。 </li></ul>
  <li><a name="20090406"></a>2009/04/06 Laplacian eigenmapを用いた、ネットワーク構造予測 
  <ul>
    <li><a href="http://scholar.google.com/scholar?hl=ja&amp;lr=&amp;q=%22supervised+graph+inference%22&amp;lr=">Vert&amp;Yamanishi(2004)</a>について考えていて、これは本質的には<a href="http://scholar.google.com/scholar?hl=en&amp;lr=&amp;q=%22Laplacian+eigenmaps%22&amp;btnG=Search">Laplacian 
    eigenmap</a>（より正確にはそのfeature版である<a href="http://scholar.google.com/scholar?hl=en&amp;lr=&amp;q=%22Locality+preserving+projections%22&amp;btnG=Search">Locality 
    Perserving Projection</a>）であるという結論に到達しました。 
    <li>V&amp;Y(2004)が、やっていることは、 
    <ol>
      <li>ノードを、ある写像によって、ある空間に飛ばし、飛んだ先で、互いに近いノードペアから順にリンクが張られていくというモデルを考える 
      <li>写像は、間にリンクをもつノードのペアが、近くに飛ぶように学習する 
      <ul>
        <li>ちなみに、論文中の目的関数は、リンクのあるペアを近づけ、リンクのないペアを遠ざけるように書いてあるが、実は、計算してみると、リンクのあるペアのみを使う目的関数と同じになります。 
        </li></ul></li></ol>です。 
    <li>写像の学習を、飛んだ先のベクトルの長さに制約を入れて（制約がないと、いくらでも近づけられてしまうので）行うと、これはまさにLaplacian 
    eigenmapになります。 
    <ul>
      <li>厳密には、V&amp;Y(2004)で用いている長さの制約は、標準的なLaplacian eigenmapのそれとは若干異なっていますが。 
      </li></ul>
    <li>これを、feature 
    vector（カーネル行列）が与えられていると思って、写像のモデルパラメータを学習するということにすると、Locality Perserving 
    Projectionになります。 
    <li>生成モデルで考えると、飛んだ先の座標が潜在変数になってて、まず、こいつが生成されて、これをパラメータとして、特徴ベクトルが生成されることになります。 
    また、潜在変数が近いやつの間にリンクが張られます。 これの離散潜在変数版が<a href="http://scholar.google.com/scholar?hl=ja&amp;lr=&amp;q=%22Learning+Systems+of+Concepts+with+an+Infinite+Relational+Model%22&amp;lr=">IRM</a>という感じ。 
    IRMとV&amp;Yモデルは、モデルの厳密さと計算のトレードオフ具合が、ちょうど、<a href="http://scholar.google.com/scholar?hl=en&amp;q=%22probabilistic+latent+semantic%22&amp;spell=1">pLSI</a> 
    (mixture of multinomial distributions) と<a href="http://scholar.google.com/scholar?hl=en&amp;lr=&amp;q=%22latent+semantic%22&amp;btnG=Search">LSI</a> 
    (PCA)の関係に似ているように思います。 
    <li>ところで、Laplacian 
    eigenmapは、飛んだ先での（ユークリッド）距離が近くなるように学習しますが、飛んだ先で相関が大きくなるようにすると、対応分析（もしくは、正順相関分析）になります。 
    （これは、V&amp;Y(2004)の2部グラフ版である。<a href="http://scholar.google.com/scholar?hl=ja&amp;lr=&amp;q=%22supervised+bipartite+graph+inference%22&amp;lr=">Yamanishi(2008)</a>でも指摘されていることです）。 
    興味深いのは、別にどっちの方法でもいいだろうと思う（むしろ後者のほうが個人的にはしっくりくる）のにもかかわらずLaplacian 
    eigenmap/LPPのほうが実験的には性能がよかったりするところです。 
    データの種類によっても変わるのかもしれませんが、僕が試した限りでもやはりその傾向は見られました。 </li></ul>
  <li><a name="20090322"></a>2009/03/22 さほど機械学習とは関係ない話 
  <ul>
    <li>「<a href="http://www.amazon.co.jp/dp/4621080504/">研究資金獲得法</a>」 
    <ul>
      <li>科研費？とか、さきがけ？とか、COE？とか言われても、どれがどれのことやら、それらの関係も、いまひとつ分かっていなかったのだが、コンパクトに情報がまとまっていて、なんとなく、分かった気がする。 

      <ul>
        <li>わりと淡々と書いてあって、読み物というよりは資料に近いかんじだが、面白かったです。 </li></ul>
      <li>ちなみに、2008年の教員1人あたりの科研費獲得件数は、奈良先端、東北大、名古屋大、京大、総研大の順らしい。 
      一方、1人あたりの額面は、総研大、東大、京大、東北大、だそうだ。 へええ。 </li></ul>
    <li>「<a href="http://www.amazon.co.jp/dp/4532110424/">知財マネジメント入門</a>」 
    <ul>
      <li>特許などで関わっておきながら、あまり仕組みを知らなかった、知財まわりの話（<a href="http://www.jpo.go.jp/tetuzuki/t_gaiyou/tokkyo1.htm">特許が成立するまでの流れ</a>など）が、わかりやすく説明されています。 

      <li>出願されたもののうち、5～6割が審査請求され、そのうち5～6割が特許として成立するらしい。 へええ。 
      <ul>
        <li>出願全体から考えると、特許になるものは2～3割なので、論文と同じくらいの採択率だが、審査請求≒査読の請求、みたいなものだと思うと、論文の採択率よりはずっと高い。 
        毎ステップでお金がかかるので、審査請求の段階で、出願人の自己評価によって審査請求の数（≒査読に回る数）が抑えられるという仕組み。 
        論文も、投稿の時点で、いくばくかのお金をとるようにすれば、むやみに採択率が低いわりには、クオリティの低い投稿多すぎ、というのを避けられるかも。 
        </li></ul>
      <li>アプリケーション分野によって研究グループが作られている場合には、座席は技術分野でまとめるのがイイ、あるいはその逆にするのがイイらしい。 
      へええ。 
      <li>「禁じられた移転」： 
      機関をまたいだ（大学→企業とか）技術移転は、研究部門→研究部門、開発部門→開発部門のように同じレベル（同じレベルの部門をもった機関間）でないとうまく行かないらしい。 
      へええ。 </li></ul>
    <li>ところで、一層関係ない話だが、「過去の成功体験に捕われるな」と言われる。 「成功よりも失敗から学べ」と言われる。 それって本当だろうか。 
    <ul>
      <li>機械学習におけるというか、予測一般における暗黙の仮定として「正例の近くには正例があり、負例の近くには負例がある」があるだろう。 
      <ul>
        <li>正例を1つ見つけたら、その周りを探せば、正例に出会える確率が高い。 
        一方、負例を1つ見つけても、そこから遠ざかれば、その周りの、よく似た負例に出会う確率は低くなるが、かといって、別に、正例に出会える確率が上がるわけではない 
        （少なくとも、正例のときほどには、上がらない） </li></ul>
      <li>これに従って考えれば、過去の成功に拘るほうがいいに決まってる。 
      <ul>
        <li>ただし、システムが短い時間において静的である、という仮定もあるわけだが、仮にそうでなかったとしても、せいぜい、正例と負例が同じ程度の価値になる程度だろう。 
        </li></ul>
      <li>が、正例だけで、負例がないと、判別学習できないよね、って思えば、まあ、そうかもしんない。 成功ばっかりの人にとっては正しいのかも。 
      <ul>
        <li>あるいは、これは人間の持つ性質についての議論だ、ってことなのかもしれない。 
        人間というのは、失敗からのほうがよりよく学ぶものなのだ、みたいなかんじ。 </li></ul></li></ul></li></ul>
  <li><a name="20090217"></a>2009/02/17 3月の<a href="http://www.iip.ist.i.kyoto-u.ac.jp/sigfpai/">人工知能基本問題研究会 
  (SIG-FPAI)</a>で、リンク予測の研究についての発表をします 
  <ul>
    <li><a href="http://www.geocities.jp/kashi_pong/publication/SDM2009.pdf">SDMで発表するやつ</a>です。 

    <li>リンク予測問題は、任意の2つのオブジェクトの間のリンクの有無を予測する問題です。 
    通常、教師付きの設定で、いくつかのオブジェクトペア間についてはリンクの有無が与えられています。 
    <ul>
      <li>応用としては、 
      <ul>
        <li>ネットワーク予測： タンパク質間相互作用ネットワーク、お友達ネットワークなどのネットワークの構造推定 
        <li>推薦システム： 商品とユーザーの間の（購買などの）関係の予測 </li></ul>などがあります （マルチタスク学習などとも関連します）。 
      </li></ul>
    <li>提案手法の売りは、 
    <ul>
      <li>たぶん、初めての「半教師付きリンク」予測法で、 
      <li>たぶん、初めての「複数種類のリンクを扱うことができる」（複数種類のリンクの相関を利用した同時予測をします）リンク予測手法で、 
      <li>リンクのもつ情報（構造情報）と、ノードのもつ情報の両方を自然に扱うことのできるリンク予測手法です </li></ul>といった感じです。 
    <li>テクニカルには「ラベル伝播法を、リンク予測に応用しましたよ」のほぼ一点に尽きますが、その結果、ノード同士の類似度（N×N）ではなく、ノードペア同士（N<sup>2</sup>×N<sup>2</sup>）の類似度を扱うことになってしまうので、そこを、ちょこっと効率化してやります。 
    </li></ul>
  <li><a name="20090212"></a>2009/02/12 集合知、もしくは、群衆の叡知みたいな話を、コッチの土俵で研究する 
  <ul>
    <li>ちょっと前の本だが「<a href="http://www.amazon.co.jp/dp/4047915068/">みんなの意見は案外正しい</a>」という本がありました。 
    専門家ではない、多くの人の意見を統合すると、専門家単体の意見よりも正しい、ということがよく起こるのです、というような話。 
    これがうまく働くには、複数の意見の独立性などが必要だよ、とか、予測そのものを株に見立てて売買し、その価格で予測を決める「予測市場」なんて仕組みがあったり、など、そんなことが書かれている。 
    とても面白い読みものです。 
    <li>こういう話は、集合知 (collective intelligence) や群衆の叡知 (wisdom of crowds) 
    と呼ばれ（イコールなのか、包含関係なのかは知らん）、ちょっと前まで、Web2.0の文脈でもてはやされていたみたい。 たぶん。 
    Wikipediaとか、PageRankとか、アマゾンのオススメとか、Webページにみんなでタグをつけたりするのが、その例らしい。 たぶん。 
    <ul>
      <li>「みん正」よりも、もそっとコッチよりの本というと、オライリーから「<a href="http://www.amazon.co.jp/dp/0596529325/">Programming Collective 
      Intelligence</a>」（<a href="http://www.amazon.co.jp/dp/4873113644/">和訳もあり</a>）なる本が出ている。 
      推薦システムや、Web文書のクラスタリングや分類などが紹介されており（<i>なんとNNMFまで！</i>）、 
      これは、イマドキの文脈での、機械学習プログラミングのテキストとして、結構いいかもしれない。 
      が、これは、どちらかというと「Pythonでつくる知的Webアプリケーション」的な話のような気もする。 </li></ul>
    <li>機械学習使ってみましたよ、だけではなく、機械学習の研究、もしくは、AIの研究として、 
    （なるべく、多少なりとも数理的な立場から）「意見の集約」を対象とした研究があるだろうか、何か面白いことができないかな、と思うのです。 
    <ul>
      <li>ところで、コンピュータを使った、意見の集約には、 
      <ul>
        <li>意見の抽出 
        <li>意見の統合 </li></ul>の２つのフェーズがあるような気がするけど、前者は、自然言語処理の人が頑張っているとこなのかな。 
      個人的には、後者の方に興味がある。 
      <li>「意見の集約」問題が、一般的な教師アリの予測問題と違うのは、過去のデータからの学習ができない、一発勝負の予測問題であるところであると思います。 
      （別に、できる設定にしてもいいけど、それだと普通でつまんない。） </li></ul>
    <li>で、力矢くんから教えてもらった論文「<a href="http://scholar.google.com/scholar?hl=en&amp;lr=&amp;q=%22Common+Voting+Rules+as+Maximum+Likelihood+Estimators%22">Common 
    Voting Rules as Maximum Likelihood Estimators</a> 
    （UAI'05）」は、「意見の集約」問題への、生成モデルの立場からの接近法を与えている（正しくは、教えてくれる）、とても面白い論文であると思います。 
    <ul>
      <li>何人かの人が、それぞれ、候補の集合から、良いと思うものを、ひとつづつ選ぶ （あるいは、集合の要素をよい順に並べる）。 
      で、それらの意見すべてを集約して、一番良いものを選びたい（あるいは、正しい順序に並べたい）が、どうやって集約するのがよいだろうか、という問題を考えます。 

      <li>まず、意見集約の2つのモデルを考えます。 
      <ul>
        <li>「みんなの意見⇒答え」モデル： それぞれの人が選ぶ候補に依存して、それを集約した結果として答えが決まるのだ。 （選挙とかはこっち） 
        <li>「答え⇒みんなの意見」モデル： 真の答えは先にあって、それをそれぞれの人が限られた知識をもとに推測して答えているのだ。 </li></ul>
      <li>この論文では、後者の立場をとる。 
      つまり、真の、最もよい候補（あるいは、正しい順序）は予め存在し、それぞれの人が選ぶ候補（あるいは、順序）は、これに、なんらかのノイズが乗って観測されたものだと考える（真の最も良い候補あるいは、正しい順序をパラメータにもつ確率分布によって生成される）。 
      で、パラメータであるところの、最も良い候補（あるいは、正しい順序）は、集まった投票から、最尤推定によって決まる、とする。 
      <li>僕が「ああ！そうだよね！そうすれば、いいんだよね！」と思ったのは、真の答え（パラメータ）⇒みんなの意見（データ）という生成過程を考え、意見の統合とは、パラメータの推定問題だ、と考えることで、みんなの意見からの答えの推定、という問題が、すごく見通しが良くなった、というところです。 
      こちら側の土俵に一気に引っ張ってくる感じだ。 
      <li>これなら、「こういうときに、統合はうまくいくよ」みたいな仮設を生成過程のモデルに組み入れてやって、その正しさを、データを用いて検証する、などということができるようになるわけです。 

      <li>まあ、実は、この見方自体は、この論文で提唱されたものではなく、18世紀にすでに提唱されていたということです。 
      というか、この論文の本題は、いくつかの標準的な勝者決定のプロトコルのいくつかが、ある確率モデルのもとでは、最尤推定になっている（あるいは、最尤推定にはならない）ことを証明する、という話なのですが、僕は、そっちより、こっちのほうに感心しました。 
      </li></ul>
    <li>別の問題設定を行った論文としては「<a href="http://scholar.google.com/scholar?q=Aggregating+Disparate+Estimates+of+Chance&amp;hl=en&amp;lr=">Aggregating 
    Disparate Estimates of Chance</a>」。 こっちは、それぞれの人が、複数の問いに答え、統合するという設定を考えています。 
    <ul>
      <li>複数の問いには、なんらかの論理的な関係が成立していることを想定する。 
      たとえば質問１と質問２に「ハイ」で答えた場合、質問３も「ハイ」でないとおかしい、みたいな感じ。 
      <li>それぞれの問いの答えを、別々に統合すると、得られた答えに対しては、必ずしも、上の論理的な関係が成り立っていないので、これが成立するように、統合する。 
      </li></ul>
    <li>ま、とりあえずは、ベンチマークデータですよね。 要るのは。 
    <li><font color="#ff0000">ところで、このエントリについては、神嶌さんにいろいろ教えていただきました。 
    ありがとうございます。</font> </li></ul>
  <li><a name="20090202"></a>2009/02/02 Putting one of your legs on the shoulders 
  of giants 
  <ul>
    <li>職場のオープンハウスにかりだされて、学生向けの講演をしました。 
    <ul>
      <li>知り合いの先生方には、学内宣伝のスパム依頼をお願いしたりなど、ご迷惑をおかけしました。 ありがとうございました。 </li></ul>
    <li>内容は、どんな感じで働いているとか、どういう仕事をしてきましたとか、そんな感じですが、最後に、企業の研究所で、なんだかんだと、10年間やってきて、企業の研究所で、よかったと思えること、メンドウだなと思うこと、大切だな、と、現時点で思っていることを紹介しました。 

    <ul>
      <li>ですがね。 概ねは、井手さんのパクりですよ。 </li></ul>
    <li>まず、企業の研究所でよいこと、これは「現実世界との（好む好まざるにかかわらない、半ば強制的な）接点」であると思います。 
    <ul>
      <li>お客さま、社内の他部門などとの仕事を通じて「現実的な工学の問題」に携わることになります。また、当然、その価値の受け手は、自分のドメインを超えた広い対象になります。 

      <li>他の研究分野との接点が多く、また、（学問的にではなく、ビジネス的な）一段抽象的な視点に触れる機会を多く持ちます。 
      <li>これらのことは、アカデミックな世界においても、大きな差別化になります。 
    </li></ul>もちろん、アカデミックにおいても、僕なんかよりずっと現実の世界に生きている方も多いと思います。 
    ポイントは「強制的」であるところ、これは、放っておくと、現実から乖離してしまう自分にとっては非常に重要な点です。 
    <li>一方、めんどくさいことは、やはり同じく「現実世界との接点」に因ります。 
    <ul>
      <li>あくまで工学です。 「わかった」ではなく「できた」が問題になります。 
      <li>最後は、ビジネスです。 自分の思う価値ではなくて、受け手の思う価値に完全に支配されます。 
      <li>変化が急に訪れます。急に、方針や組織が変わったりします。 時には、思いがけず、仕事の内容が変わることもあります。 </li></ul>
    <li>このような状況のなかで、なるべく、自分が楽しいことを、少しでも長く続けるために、ある程度の努力を割く必要があると思います。 
    努力の仕方として、とりあえず、2つの頑張りかたがあると思います。 
    <ol>
      <li>チーム、個人、それぞれにおいて、<a href="http://ja.wikipedia.org/wiki/%E3%82%AD%E3%83%A3%E3%83%A9%E7%AB%8B%E3%81%A1">キャラ立ち</a>すること： 

      <ul>
        <li>「（雇い手がうれしいであろう）これができる人／チーム」という名札をつけることが、楽しい環境を維持し、また、その新たな機会を得るためには、極めて重要であると思います。 
        </li></ul>
      <li>そして、それをいくぶん<font color="#ffff00">★</font>ギラギラ<font color="#ffff00">★</font>と、アピールすること： 
      <ul>
        <li>「<a href="http://en.wikipedia.org/wiki/Standing_on_the_shoulders_of_giants">巨人の肩に立つ</a>」という言葉がありますが、過去の研究に敬意を払うのは基本ですが、時には、全部さらっていくようなずうずうしいアピールも必要だと思います。 
        企業研究者は「巨人の肩に、片足だけ立つ」くらいが丁度いいんじゃないかと思います。 
        <li>逆に、さほど腹黒さを発揮しなくても、「おれ（達）イケてます」と言いやすい場所を見つけるのが本質ではないかとも思います。 
      </li></ul></li></ol>
    <li>んが、けっきょく、<a href="http://www.geocities.jp/kashi_pong/kyojinnokatanikataashidaketatsu.jpg">この絵</a>を出したかっただけちゃうんか、といわれると、ハイ、そうです、そのとおりです。 
    </li></ul>
  <li><a name="20090109"></a>2009/01/09 昨年のまとめと今年の方針 
  <ul>
    <li>去年も、主に、頂き物で構成された、随分と大漁な一年でした。 
    <ul>
      <li>今年も早速、杉山さん、八岳さんたちに混ぜていただいた、強化学習の話が、ICRA（ロボ系）に採択されました。 ありがとうございます。 
    </li></ul>
    <li>今年も、頂ける体制を維持しつつ、1つくらいは、自分で何かやりたいと思います。 
    <li>特に、「無理な体勢からのヒット」 を打てるようになりたいところです。 </li></ul></li></ul>
<hr>

<p>ちなみに、このサイトの掲載内容は私自身の見解であり、必ずしもIBMの立場、戦略、意見を代表するものではありません</p><script type="text/javascript" src="http://www.google-analytics.com/urchin.js">
</script><script type="text/javascript">
_uacct = "UA-1197929-1";
urchinTracker();
</script></body></html>
