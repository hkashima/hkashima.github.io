<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"> 
<html><head><title>機械学習についての日々の研究</title>
<meta http-equiv="Content-Type" content="text/html; charset=Shift_JIS">
<meta content="MSHTML 6.00.6000.17093" name="GENERATOR">
<meta http-equiv="Content-Style-Type" content="text/css"></head>
<body>
<p><a href="http://www.geocities.jp/kashi_pong/index.html">もどる</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2012.html">2012年の日記</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2010.html">2010年の日記</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2009.html">2009年の日記</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2008.html">2008年の日記</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2007.html">2007年の日記</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2006.html">2006年の日記</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2005.html">2005年の日記</a> 
<a href="http://www.geocities.jp/kashi_pong/research_diary-2004.html">2004年までの日記</a></p>
<p><font size="+2"><b>（か）研究日記</b></font></p>
<hr>

<ul>
	<li><a name="20111229"></a>2011/12/29 今年も終わり
	<ul>
	<li>ことしも（計算機的な意味では）自らの手をほぼ動かすことなく終了。「毎年ひとつは自分でやる」の目標は、なかなか達成できない。
	<ul>
		<li>これはこれで一度にたくさんのことをできるので、自分には合っている。
		<li>得意な人に部分問題を振るスタイルに迷いがなくなったところがおとなになった感じ。
	</ul>
	<li>今年は、数年前からやりたかったクラウドソーシング系の話を（学生と一緒に）はじめられたのがうれしい。
	<ul>
		<li>ただ、じゃっかん出遅れてしまった感じ。 自分には数年前の混沌とした段階で始める力がなかった、というのが反省。
	</ul>
	<li>今年は、２つ賞のを（１つは間接的に）いただいた。
	<ul>
	<li>ひとつは、情報処理学会からいただいた山下記念研究賞で、これは研究会発表の中から選ばれる賞。 
	昨年に沖縄で開催されたバイオ情報学研究会で発表した、複数生物種の生体ネットワークを同時に予測する方法（共著は（パリのほうの）山西さん、加藤さん、杉山さん、津田さん）についての研究に対していただいた。
	<li>もうひとつは、ECML/PKDDでの最優秀学生論文賞（データマイニング部門）で、昨年度卒論生だった成田くんが筆頭著者、NAIST D3の林さんが学生＋冨岡さん（これはプロの人）として共著に入っている、補助情報をもちいたテンソル分解についての論文についての受賞。
	</ul>
	<li>褒められることは、当然うれしいわけだが、それぞれのうれしさがある。
	<ul>
	<li>前者は、IBMにいたころ、当時MPIにいた津田さんのところで進めた研究で、これの論文版はBioinformatics誌に載ったもの。 
	以前の日記にも書いたように、この論文は「自分、バイオインフォマティクスやったことあるっす！」という（ほぼ唯一の）証拠ともいえる論文であり、（あと、研究実施者としての、ほぼ最後（？）の研究という意味でも）これが褒められたというのは大変うれしい。
	<li>後者は、まずは研究指導者としての自分を褒められたということ。 また、初の国際的な舞台での褒められであること。 自分としても、そろそろ「国内～APレベル」をウロウロしているという状況を脱したい。
	</ul>
	<li>ところで、両者の研究に共通しているのは、何らかの意味での情報統合（従来使っていた情報＋これまでに使われていなかった情報の利用）についての研究であることである。
	<ul>
	<li>前者は、各生物種ごとのもつ情報に加え、複数生物を横断する情報を用いることで、複数生物種種ネットワークの同時推定が可能になったという話。
	<li>後者は、テンソルの低ランク性の仮定に加え、補助情報としてエンティティ間の関係情報を用いることで、テンソル分解の推定精度を上げるという話。
	</ul>
	どちらも、ある意味でズル情報を加えることで予測精度を上げるということで、問題設定の時点でほぼ「勝ち」が見えている。
	<li>機械学習を適用するうえで最も重要なのは、結局のところ、どういう情報をどう表現して使うか、つまり：
	<ul>
	<li>１）有用な情報をなるべくたくさんつかう（情報の獲得・選択）
	<li>２）情報を適切に表現する（特徴の設計）
	</ul>
	というところであると思っている。
	<ul>
	<li>たとえば、タンパク質の機能予測をするために、遺伝子発現情報だけでがんばるより、配列情報やアノテーション情報があるのだからそれを使った方がいい。画像検索をするのに、画像だけでがんばるよりも、テキスト情報があるなら使うべき。
	</ul>
	<li>そして特徴の設計は最重要といっていい。 決定木だとかSVMだとかのモデルの違いや、何基準でモデル選択するかの違いなんて、特徴の違いに比べれば些細なことである。
	<ul><li>
	いや、もちろん重要なんだけど、そんなに人いらんだろ、という感じ。
	</ul>
	<li>特徴の設計等に関する部分は、なかなか一般的に考えづらく、「機械学習」的な研究になりにくいところもあるが、そこをなんとかやる、というのは大切だと思う。
	<ul><li>
	設計そのものの話ではないが、MKL的な話は（実際なかなかうまくいかないところはあるけど）手法的な美しさを兼ね揃えた、すごくいい線いっていると思う。
	</ul>
	<li>特徴設計などは、なかなか一般論にはならないので、どうしてもドメイン依存になり、機械学習の人の価値観からは下に見られがちだが、それでもなんとかせめてドメイン内では共通に使える特徴を設計するのが重要。 SIFTとか、よくわかんないけど、ほんとスゴイと思う。
	<li>SIFTスゴイ！ 全然意味わかんないけど。
	</ul>
	<li><a name="20111213"></a>2011/12/13 パーソナライゼーションとバリエーション
		<ul>
		<li>機械学習、特にその自然言語処理やコンピュータビジョンへの応用において、クラウドソーシングを用いたデータ収集が盛んに行われつつある。
		たとえば、教師付き学習のラベルをクラウドソーシングを用いて、比較的安価に収集できる。
		当然、データの質はコントロールされた状況と比較して落ちるので、そこをいかに補正するかが考えどころとなる。
		<li>クラウドソーシングを用いた教師付き学習の定式化としては、通常の教師付き学習が訓練データとして(入力, ラベル)の形を想定していたのに対し、こ
		こにさらにラベルをつけた人のID情報が入り(入力, ラベル, ラベラーID)という形式のデータがあることになる。
		テクニカルには、ラベラーIDを、つまり、ラベラーごとのラベル付けの能力や傾向をうまくモデルに取り込むことがポイントになる。
		<li>その他、(入力, ラベル)の他にも情報があるような問題としてはマルチタスク学習と呼ばれる設定がある。
		マルチタスク学習とは、複数の関連する（教師付き）学習タスクを同時に取り扱うことで、各タスクのデータ不足を解消し、全体として精度を上げようというものである。
		ここでは、(入力, ラベル, タスクID)という形のデータが与えられることになる。
		<li>訓練データの形式からも分かるように、マルチタスク学習とクラウドソーシングを用いた学習はとてもよく似ている。
		両者とも、タスクであったり人であったり、対象の性質が（ある部分を共有しながらも）それぞれに異なることを意識し、これを明示的にモデル化しようとするものである。
		マルチタスク学習におけるタスクと、クラウドソーシングを用いた学習におけるラベラーを同一視すると、両者はほぼ同じであるように思えてくるのだが、実は大きな違いがある。その違いは、目的の違いにある。
		<li>マルチタスクにおけるタスク＝一人の人と対応させると、マルチタスク学習では、個々人に対してそれぞれに適応したモデルを得ること、つまりパーソナライゼーションを行うのが目的となる。
		ここでは個々のモデルはそれぞれの真実を表していると考える。
		一方、クラウドソーシングを用いた学習の場合、最終的に欲しいのは、ただ一つの真のモデルである。
		個々人が生成するデータ（もしくはその生成過程）はあくまでバリエーションであると考えるのである。
		<li>両者の共通点（と差異）を意識することで、両者の知見をモデルに取り込むこと
		（研究としてはマルチタスク学習の方が進んでいるので、前者の知見を後者に、となるだろう）
		が有効になると思う。
		</ul>
	</li>
	<li><a name="20111128"></a>2011/11/28 機械学習研究の終焉
		<ul>
		<li>最近、猫も杓子も機械学習で、大変よいことである。
		アカデミアだけでなく、さまざまな企業が、機械学習に限らず（大量の）データ分析を重要な要素として位置づけているようであり、
		その真偽のほどはともかく、少なくとも自分としては「ここだ」というヤマが当たったという感じで嬉しい。
		このあと、かつてのAIブームのようなガッカリ感が来るのかどうかはわからないが、（機械学習もAIだと思うと）今回のブレイクは「ちょっと盛り気味」くらいの期待だといいなと思う。
		<li>さて、世の中で広く使われるようになってきたということは、（まだできないことはいろいろあるけど）今届く範囲にやりたいことがそこそこ含まれるということであり、
		それはある程度技術としては成熟したということであり、もっというとコモディティ化が進んでいるということでもある。
		これは、これから機械学習を自らの専門性の軸としようとする人は注意したほうよいかもしれない。
		いまや普通のエンジニアまでもが機械学習がー機械学習がー…と口にし、
		「機械学習」を冠する技術書が普通に出版され、
		それにより機械学習（の特に役に立つ部分について）は誰にでも使えるようになり、
		結果として、差別化要因となる専門知識としての機械学習の価値は弱まり始めているように思う。
		<li>まあ、研究者としては、楽しく自分のやりたいことを研究できたらいいじゃん！ということではあるのだが、やはり、
		（個人的には）お祭りがすっかり去った後もずっとそこに居続けるよりは、お祭りを先回りして、そして、その最高潮の瞬間に居合わせたいところである。
		先ほど述べたように機械学習には、まだできないことはいくらでもあるし、研究分野としての機械学習（＝お祭り）はもうちょっと続くと思う。
		だが問題なのは、機械学習が「オワコン」となったときに、それに気付けるかということである。
		ホントのお祭りと違い、まっただ中にいるとむしろそのことに気付けない。
		中にいると、まだまだやるべきこと、やりたいこと、いくらでもあるし、まだまだ全然イケると思っているが、外からみるとそうでもない、というのは他の分野を見ているとあるように思う（どことは言わないが）。
		</ul>
	</li>
	<li><a name="20110826"></a>2011/08/26 「クラスタリングの呪い」解ける
		<ul>
			<li>クラスタリングといえば、K-meansや階層クラスタリングがまず思い浮かぶ。
				これらは局所探索もしくは貪欲法によって「準最適解」にたどりつくような方法であり、
				そもそもクラスタリングとは（あくまで何らかの目的関数の最適化という意味では）最適解など求まらないものである、と（すくなくとも自分は）思いこんできた。
				K-meansや階層クラスタリングがあまりに定番すぎることで、そこからなかなか抜け出ることができなかったということなのかもしれない。
			<li>ところが、ここ数年、K-meansと階層クラスタリングによってかけられた「古の呪い」が解けつつあるのではないかと感じている。
				凸最適化によって疎な解が得られるスパース正則化法（lasso, group lasso, fused lasso, structured sparsity）や、その他の新しいクラスタリングの定式化の提案などによって、必ず「最適な」クラスタリングが求まるという研究が出てきつつある。
			<li>そこでの多くの方法に共通して現れる基本的な考え方は「1データ⇔1クラスタ」の定式化であるように思う。
			つまり、K-meanクラスタリングにおける非凸性の元凶である「クラスタへのデータの所属割り当て」の問題を、各データはそれ自身のためのクラスタに所属するとしてしまうことでこれを回避する。
			<li>たとえばNIPS2007の論文「<a href="http://scholar.google.co.jp/scholar?q=Convex+Clustering+with+Exemplar-Based+Models">Convex Clustering with Exemplar-Based Models</a>」では、クラスタ中心の位置を、与えられたデータの(exemplarもしくはmedoidとよばれる)上に限定した場合を考えている。
			<ul>
			<li>すべてのデータのうえに固定幅のガウス分布（でもなんでもいいけど）を置き、これらの混合分布としてデータを表現する。
			混合比だけを推定するので当然凸最適化で、また、混合比は確率的な制約なので最終的な解において利用されるクラスタ中心の数は少なく（疎に）なる。
			<li>考えてみるとなんか当たり前なんだけど、こんなことが陽に言われていなかった、というのは、やはり呪いのような気もする。
			</ul>
			<li>先日の<a href="https://sites.google.com/site/icml2011reading/home">ICML2011読む会</a>で紹介されていたクラスタリングの正則化パスを求める論文「<a href="http://www-als.ics.nitech.ac.jp/%7Etakeuchi/110804TPrimal/tprimal110804.takeuchi.pdf">Clusterpath:～</a>」では、スパース正則化をもちいて、クラスタリングの問題をうまく定式化していて面白い（実は、数年まえに<a href="http://scholar.google.co.jp/scholar?hl=ja&q=Convex+clustering+shrinkage">ほぼ同じアイディア</a>がでていたりするのではあるが）。
			<ul>
			<li>これは各データがひとつづつクラスタ中心をもっていて（つまりデータの数だけ中心がある。データと中心は一致しなくてもよい）、
			お互いに近いデータのもつクラスタの中心同志の差に対してスパース正則化（fused lasso）を行うことで、複数のクラスタ中心が縮約するという仕組み。
			言い換えると、相対位置が0、つまり完全に一致するクラスタ中心対が増えるので、結果として見た目のクラスタ中心の数が減る。
			<li>差分を0にする力を調節する正則化パラメータを徐々に変えることで、階層化クラスタリングのような絵も（正則化パスとして）描ける。
			</ul>
			<li>あと、これらとはまた異なるアプローチとして、予測モデルのクラスをクラスタのラベルだと思って、モデルとクラスの両方を最適化する（要は、予測が当たるようなクラスわけをする）というものもある。<a href="https://sites.google.com/site/icml2011reading/home/ICML2011reading.pdf?attredirects=0">杉山さんのやつ</a>では、固有値一発で大域解が求まってしまう。
	</ul>
	</li>
	<li><a name="20110824"></a>2011/08/24 「研究は何をやるか決めた時点で8割方終わっている」か？
		<ul>
			<li>この言葉は、自分が入社間もないころ（つまり修士出た直後）に、その後長く上司だった人から言われた（ような気がする）ことなのだが、これを初めてきいたとき、まがりなりにも数理工学出身である（いや、むしろ未熟な数理工学心をもっていたからこそ）自分は随分と抵抗を覚えたように記憶している。というのも、当時の自分にとって研究の価値とは「与えられた問題をみんなが驚く数理的に高度なテクニックで格好よく解いてみせる」ことにあり（ギターだって速ければ速いほどいいよね！）、それを、どの問題を解くか決まった時点で終わっているよ、と言われるなど、存在の否定である、許せない、ということなのだろう。
			<li>しかし、今現在では、上記の言葉は、少なくとも工学研究者についていえば8割方正しい（もちろん例外はいくらでもある）と思っているし、そのような考え方でやっている。
			<ul><li>「そもそも何をやっているか」のレベルで既に勝ちが確定していて、あとは、さらに技術的にも優れていればなお良しだよね（というか、そっちはできるでしょ、好きでやってんだから）という感じである。
			</ul>
			<li>職業研究者の役割は、研究によって社会的もしくはビジネス的に「インパクト」をもたらすことであり、そのインパクトの大きさの比較では、零のものを非零にするのと、非零のものをn倍にするのがだいたい釣り合うような感覚であるように思う。
			<ul><li>
				逆に言えば、すでに非零のものに取り組んでもいいけど、だったらn倍にしてね、ということなのだろう。
			</ul>
			<li>あれ？ もしかして、じつはこれは社畜根性というやつだっだりするのだろうか。
			<li>ところで、ものごと当初の思惑通りに進まないことはいくらでもあるし、生まれたときにはてんで何のためにあるのかわからなかったものが、後に予想もされなかったかたちで役に立つ、という話も聞く。
が、自分としては生きているうちに褒められたいなあ。言ったそばから褒められたいし、やったらすぐに褒められたいし、あわよくば、そのあともずっと褒められたいよね。
	</ul>
	</li>
	<li><a name="20110715"></a>2011/07/15 （統計的）機械学習界の風景
		<ul>
		<li>学生に話をしていて「世の中にはベイジアンとそうでない人がいる。 前者はまずグラフィカルモデルを書くし、後者はとにかく目的関数を定義する習性がある」という世の中（統計的機械学習界）の話をしたあと、結局のところどう言うのが適切なんだろう？と考えた。
その結論として、いきなりまずベイジアンかそうでないかで分類するのではなく「機械学習におけるモデル化には、生成モデル化 と 判別モデル化 の2つの立場があるよ」というほうが良いように思う。（※：「判別モデル化」という言い方がよいのかどうかはちょっとわからない）
		<li>要は、モデル化の流儀として、全体に注目する生成モデル化と、部分に注目する判別モデル化という2つのアプローチがあって、ベイジアンとか非ベイジアンなどというのは、生成モデル化、判別モデル化のそれぞれにおいて「好んで」扱われる（必要条件ではない）問題や方法に対応して、なんとなく言われているにすぎず、実はモデル化に対する態度の違いのほうが本質的であるという気がする。もぐりなので断定はできんけど。
		<li>生成モデル化と判別モデル化の定義は、おおむね：
		<ul>
		<li>生成モデル化は、見えているもの全て（教師つきデータの場合は入力と出力全部）が生成される過程をモデル化すること
		<li>判別モデル化は、与えられるもの（入力）から、欲しいもの（出力）が生成される過程のみをモデル化すること
		</ul>
		という感じで、要は、モデル化のスコープが、全体なのか（その中の）一部なのかという違いなのだろう。
		<li>ぬる機械学習な日常では、前者がベイジアン、後者はそうでない人に大まかに対応させて話されることが多い。
			しかし、これはあくまで、それぞれがフィットする機械学習の問題や使われるワザの種類が、生成モデル化と判別モデル化のそれぞれと結び付くことが多いよねという話であって、これを真に受け、まず世の中をベイジアンとそうでないものに分けるのはミスリーディングであるように思う。
		<ul>
		<li>たとえば、前者は教師なし学習において、後者は教師つき学習において用いられることも多いが、それは必ずしも必要ではない。
また、生成、判別どちらのモデル化においてもいわゆるプレート表記（「ベイジアン」を象徴するグラフィカルモデル）は用いることはできるが、前者のほうでより頻繁に用いられる。 後者だと「箱を3つ繋げて終わり」のようになるケースが多く、あまりメリットが感じられないことが多いのだろう。
		<li>前者では、興味のないパラメータを積分消去する方法というのが良く採られ、そのための諸々のテクニックもまた「ベイジアンな」イメージに対応している。
一方、後者を非ベイズあるいは頻度主義などというのもあまり適切ではなく、こちらとて（やはりベイズ的な考えかたであることには変わりない）MAP推定を行うことが多い。
ただ、これは正則化として解釈する人も多く、また手法的にも数理計画的な問題設定（目的関数の定義）と最適化のテクニックが用いられ、これが非ベイズなイメージとなっているのだろう。
		</ul>
		<li>ところで、気をつけないといけないのが、モデル化は学習とは別のものということである。 
たとえば、たまにVapnikの原理的な気持ちで「判別タスクなのだから、前者に属するナイーブベイズよりも後者に属するロジスティック回帰のほうが適切である、それはやりたいことをダイレクトにやっているからだ」というようなことを言ったりするが、これは学習手法とセットにした前提での話をしているのであって、ナイーブベイズモデルであっても「判別的な学習」を行えば、「やりたいことをダイレクトにやる」ことができる。
（ただ、実際に計算する段になると、今度は最適化問題としての質の良さも絡んでくるので、そこで後者のほうが単純なので扱いやすい、ということはあるだろうけど。）
		</ul>
	</li>
	<li><a name="20110518"></a>2011/05/18 CPS Week に参加しました
		<ul>
		<li>成り行きで、サイバーフィジカルシステム関連会議の共同開催である<a href="http://cpsweek2011.cs.illinois.edu/">CPS Week</a>に参加してきました。 
		<li>成果物は文科省に提出する報告書なのですが、<a href="CPS.pdf">センサーネットワークのデータ解析についてのいくつかの発表についてまとめたもの</a>を置いておきます。
		<li>発表には（考えてみればそりゃそうだろ、ですが）意外に制御系の話が多く、うっかり変な汁が出そうになりました。
		<li>というか、そもそもCPSって何だよという方には、<a href="http://precise.seas.upenn.edu/events/iccps11/Readings.html">ここ</a>とかにホワイトペーパー的なものがいくつかあります。
		（このノリはなんか既視感。 また汁がでそうに）
		<li>ところで大学に移ってきてからは、国際会議に自分の口頭発表なしで参加する機会がちらほらあるようになりました。 
		最初は楽チンだぜﾌﾞﾋﾋとか思っていたけど、やっぱりなんかもの足りないというか、参加してる感がいまひとつ。
		<li>来週のPAKDDでは、成り行き上、ひとつ発表します。
		</ul>
	</li>
	<li><a name="20110330"></a>2011/03/30 IBISML研究会-大阪
		<ul>
		<li>各方面でいろいろ大変なことが起こっているなか、今年度最後のIBISML研究会に半分だけ参加してきました。
		<li>今回の発表のなかで自分が関連するのは、卒論で成田くんにやってもらった<a href="publication/IBISML4_tensor.pdf">テンソルの話</a>と、諏訪くんにやってもらった<a href="publication/IBISML4_MKL.pdf">マルチカーネルPCAの話</a>（こっちは<a href="publication/IBISML4_MKL_slides.pdf">僕が発表</a>）です。
		<ul>
			<li>テンソルのほうは、低ランクテンソル分解を用いた要素補完（観測された一部から、未観測の部分を予測する問題）の話です。 
			観測部分が疎な場合には、低ランク性の仮定だけでは補完精度が十分でないので、外部情報（どの要素とどの要素が似ているか）を正則化に用いることで、予測精度を上げようというものです。
			<li>もうひとつの発表では、複数の情報源から得られたデータに対する主成分分析法を提案しています。 
			PCAの2ノルム制約をグループラッソで使われる制約に替えることで、情報源の選択機構を（いちおう、なんとなく）実現しています。
		</ul>
		<li>今回の収穫は、<a href="http://ibisml.org/archive/ibisml004/ibisml004-invited-kameya.pdf">確率＋論理のプロの方の講演</a>を聴けたこと。
		こういう全体感を持っている人に話をしてもらうと、少し見通しが良くなるかんじ。
		ずっと差がわかんなかった、関係マルコフネットワーク（Relational Markov Network）とマルコフ論理（Markov Logic）が違うというのがなんとなく、なんとなく、なんとなく。
		</ul>
	</li>
	<li><a name="20110214"></a>2011/02/14 クラウドソーシングと機械学習（NIPS読む会）
		<ul>
			<li>恒例の<a href="https://sites.google.com/site/tprimalnips2010/">NIPS読む会</a>に途中参加途中退場
			<li>岡野原さんは、学習アルゴリズムをいかに分散並列化するかみたいな話（<a href="http://lccc.eecs.berkeley.edu/papers.html">ワークショップ</a>）を紹介
			<ul>
				<li>通常、学習は逐次的なアルゴリズムなので、データを分散して、別々に学習したパラメータを持ち寄って最後に平均化するようなのでは上手くいかないらしい（この「うまくいかない」方法とbaggingの違いはよくわからなかった）
				<li>そこで、簡単な変更を加える。データを分散して、別々に学習するが「ときどき」持ち寄ってパラメータを平均化して、各自それを持ち帰って学習を続けるという方法がすごくうまくいくうえに、収束性の証明もできるらしい。
				<li>実はこれは、プライバシ保護データマイニングに結構マッチするんじゃないかと思う。 
				<ul>
				<li>データをお互いに明かすことなく、分散アルゴリズム＋暗号のテクニックで、全データを使ったモデルをつくるタイプの話があるが、これらは大抵、暗号化やら通信やらのコストで、普通にやるのに比べてすごく時間がかかってしまうのが課題。 
				<li>でも、この方法をベースにしている限りは、たまにパラメータを持ち寄って平均化するところだけを安全にやればよいので、かなりコストが抑えられるように思う。
				</ul>
			</ul>
			<li>かしまは<a href="http://books.nips.cc/papers/files/nips23/NIPS2010_0577.pdf">The multi-dimensional wisdom of crowds</a>（と、そこに至る歴史的経緯）を紹介しました。（資料は<a href="NIPS2010_readinggroup_kashima.pdf">ここ</a>）
			<ul>
				<li>かしまの「群衆モノ」への憧れは、本日記において、過去になんども触れていることからうかがい知ることができますが、今回、いろいろと論文をまとめ読みしてみて「このあたり、もうちょっとイケるよ！」と思ったしだい。
				<ul><li>
				ちなみに、学生時代のトラウマで、制御理論と強化学習にも少なからぬあこがれを抱いているのですが、でも、そんな好きな気持ちとは裏腹に「XX使えねー」とか「XX終了じゃね」などと意地悪発言をしてしまうツンデレなところがあります。
				</ul>
				<li>さて、1970年代後半に複数の医者の診断を統合する文脈で始まった「専門家の意見の適切な統合」問題では、各専門家の意見の単純な多数決よりも良い判断を下すことを目的としていました。
				先駆的な研究はおそらく<a href="http://www.jstor.org/stable/view/2346806">これ</a>で、潜在的な正解ラベルに対して、各専門家が確率的に雑音を加えたものが観測されるという生成モデルで、EMアルゴリズムによって真の正解ラベルを推定します。
				<li>そして、 2000年代に入ってからインターネット経由で安価な労働力を調達できるクラウドソーシング（特にAmazon MechanicalTurk）が教師つき学習のラベルづけを安価に行う方法として、とくに自然言語処理やコンピュータビジョンといった、機械には難しく、人間には比較的簡単なタスクを行う分野において盛んに利用されるようになりました。たぶん、自然言語処理の人たちの間では、<a href="http://portal.acm.org/citation.cfm?id=1613751">2008年のこれ</a>が結構話題になっていたような気がします。
				<ul>
					<li>↑これのもうひとつスゴイところは、<a href="http://sites.google.com/site/nlpannotations/">データががっつり公開</a>されているところ。 MechanicalTurkは日本からは使えないようなので、これはありがたい。
				</ul>
				<li>そして、そこでは多数の（素）人から集められたラベルの信頼度を上げるための手段として（「専門家の意見の統合」から「群衆の意見の統合」へと文脈を替え）、70年代の意見統合のワザが再注目されました。
				<li>そして今、これがさらに「群衆の意見からの<u>学習</u>（複数の教師からの学習）」へと進化し、ひそかに盛り上がりつつあるのでは！と思っています。
				<li>個人的には、最近の重要な進展は2009年の「<a href="http://portal.acm.org/citation.cfm?id=1553488">特徴ベクトルの導入</a>」（<a href="http://scholar.google.co.jp/scholar?cluster=5937078347373713976&hl=ja&as_sdt=0,5">これも</a>）、「<a href="http://scholar.google.co.jp/scholar?cluster=6264635615432896538&hl=ja&as_sdt=0">問題ごとの難易度の導入</a>」、「<a href="http://portal.acm.org/citation.cfm?id=1557053&dl=">オンライン化</a>」ではないかと思っています。 
				<ul>
				<li>とりわけ「特徴ベクトルの導入」は特に重要であると思います。
				<li>問題に特徴ベクトルを考えるというのは当たり前な気がするんだけど、それによって汎化（ワーカーがラベルづけしないデータに対しても予測できる）が可能になったというのが実はブレークスルーなんじゃないかと。
				<li>また、「機械学習を使い信頼できるラベルをつけた後、 そのラベルを用いて（ここでようやく特徴ベクトル投入）予測モデルをつくる」というやり方から「（ラベルの信頼度を考慮に入れつつ）最初から予測モデルをつくる」という方向にシフトしたともいえます。 最終的に解くべき問題をより直接的に解いているという意味で、みんな大好きVapnik流なんじゃないか、と。
				</ul>
			</ul>
		 </ul>
	</li>
	</ul>
</ul>
<hr>

<p>ちなみに、このサイトの掲載内容は私自身の見解であり、必ずしも所属機関の立場、戦略、意見を代表するものではありません</p><script type="text/javascript" src="http://www.google-analytics.com/urchin.js">
</script><script type="text/javascript">
_uacct = "UA-1197929-1";
urchinTracker();
</script></body></html>
<!-- text below generated by server. PLEASE REMOVE --></object></layer></div></span></style></noscript></table></script></applet>
<link href="http://bc.geocities.yahoo.co.jp/js/no.css" rel="stylesheet" type="text/css"><script language="JavaScript">var jps=382116061;var jpt=1293540392</script><script language="JavaScript" src="http://bc.geocities.yahoo.co.jp/js/no.js"></script><script language="JavaScript" src="http://bc.geocities.yahoo.co.jp/js/geov2.js"></script><script language="javascript">geovisit();</script><noscript><img src="http://visit.geocities.jp/visit.gif?jp1293540392" alt="setstats" border="0" width="1" height="1"></noscript><IMG SRC="http://bc.geocities.yahoo.co.jp/serv?s=382116061&t=1293540392" ALT=1 WIDTH=1 HEIGHT=1>
