<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=Shift_JIS">
<meta http-equiv="Content-Style-Type" content="text/css">
<title>研究メモ</title>
</head>
<body>
<p><font size="+2"><b>（か）研究日記</b></font></p>
<hr>
<p> 研究に関連する事柄についてのメモなど。
  必ずしも時系列順に追加されるわけではないよ。
  内容はその日付時点における認識だよ。</p>
<p> <a href="index.html">もどる</a> 
<hr>

  <UL>
  <LI><A name="20190918"></A>2019/09/18 クラウドソーシングと機械学習
  <UL>
    <LI> JMLRで発表されたクラウドソーシングにおけるインセンティブデザイン等でアクティブなMSRの研究者によるサーベイ論文
      「Making Better Use of the Crowd: How Crowdsourcing Can Advance Machine Learning Research」
    <LI> 機械学習とクラウドソーシングの接点を、①データ生成 ②モデルの評価 ③人間と機械の協調系 ④人間の行動研究 の4つの観点から紹介している
    <LI>① データ生成
      <UL>
<LI> 人間が生成するデータの品質の担保が主な興味。アプローチとしては2つに大別される。
<LI> ひとつは、冗長化によって複数人から得た答えを（統計的手法によって）統合して信頼性の高い答えを得る方法。色々あるけど基本的にはド定番のDawid&Skeneが結構安定して優秀 (Zhaeng et al., 2017)。
<LI> もうひとつのアプローチは、人間が高い品質の結果を返すようなインセンティブ設計（主に成果報酬の設計）。Peer predictionの枠組みがしばしば用いられる。基本的には、大多数の人と同じ回答を答えたほうが報酬が高くなるようにすることで、自分が最も正しい思っている答えを正直に答えたほうが得するような仕組み (Radanovic et al., 2016)。
<LI> フリーフォーマット回答
  </UL>
    <LI>② モデルの評価
      <UL>
        <LI> 教師なし学習のモデルを人間が評価する。たとえばトピックモデルの見つけたトピックが正しいかどうかの評価。トピックは、それを代表する単語の集合によって与えられるが、この中に、他のトピックの代表語を混ぜて、これを人間が見つけられるかをテストする。代表語がトピックをうまく表現していれば、混ぜられた単語が簡単に見つかるハズ（たとえば、食べ物に関する単語群の中に、政治用語が混ざっていたら簡単に見つけられる）である。
        <LI> 教師付き学習モデルの予測の説明を評価させる。最近流行の説明可能AI（XAI）では様々な説明手法が提案されているけど、その評価は困難。二つの異なる予測器の予測を人間に提示して、どちらが正しそうかを判断してもらう。説明を不可することで、判断の精度が上がるならば、その説明が役に立つといえる。
        <LI> モデルパイプラインの検証。コンピュータビジョンや言語処理などのパイプラインにおいて、その一部の要素を人間（クラウドソーシング）で置き換えることで、パイプライン全体の精度の変化をしらべる。人間で置き換えることで大きく精度が上がるようなら、その要素がボトルネックということになる。
      </UL>
    <LI> ③ 人間と機械の協調系（human-in-the-loop）
<UL>
  <LI>ハイブリッドクラスタリング：たとえば人物画像をもとに、それが俳優か政治家かという観点でクラスタリングするのは人間の知識が必要。人間が類似度評価をした結果をまとめて、クラスタリングをする。
  <LI>その他の実例としては、リアルタイム書き起こしや、学会のスケジューリングなどを行た事例などもある。
  <LI>人間と機械によるハイブリッド予測：予測市場に代表されるような人々の予測を引き出し統合して予測を行うような仕組み。予測市場では、当たると$1もらえるような証券を売買すると、確率pで当たると思っているひとは証券価格がpより小さければ買う、逆にpより大きければ売るので、最終的に証券価格が皆が平均的に思っている確率に収束する。Atanasovら (2017)は、予測市場を用いなくても、予測投票をうまくやればよりよい予測ができることを示している。
    </UL>
<LI> ④ 人間の行動研究
  <UL>
<LI> 心理学研究におけるクラウドソーシングの利用；クラウドソーシングを用いた心理学実験は、Buhrmesterらが心理学コミュニティにクラウドソーシングを紹介した論文（5500件以上の引用！）以降、増加している。 いっぽうで、皆がクラウドソーシングを実験に使うことで、ワーカーがこの手の実験に慣れてしまっているという指摘もあるらしい…。
<LI> そのほか、人間が機械学習の予測をどの程度信頼するかの調査やオンライン広告へのユーザの反応調査などにも使用されるようだ。
  </UL>
  </UL>    
</UL>
      
      
<UL>
  <LI><A name="20190725"></A>2019/07/25 Kervolutional Neural Networks （カーネリ込みニューラルネットによる畳み込み操作の非線形化）
  <UL>
    <LI> ExaWizards主催のCVPR2019勉強会における論文紹介（<a href="CVPR2019Reading_Kashima.pdf">スライド</a>）
    <LI> CNNにおける畳み込み操作（線形）をカーネルで非線形化しようというもの。
    <LI> いわゆるカーネル化よりは弱いけど、「Kervolution（カーネリ込み）」の出オチ一発芸が好み。
  </UL>    
</UL>

<UL>
  <LI><A name="20190307"></A>2019/03/07 Human-in-the-Loop Feature Selection (特徴量選択を教師付き学習する)
  <UL>
    <LI> ExaWizards主催のAAAI2019勉強会における論文紹介（<a href="AAAI2019Reading_Kashima.pdf">スライド</a>）
    <LI> 訓練データにおいて、どの特徴が重要かという補助情報（たとえば専門家の注釈など）が与えられている状況を考え、
         これを使って特徴選択器も（教師付き）学習しようというアイディア。
    <LI> 説明可能性の文脈で同じような設定を考えていた（が我々は上手くいかなかった）ので、見事にやられた。素晴らしい。
  </UL>    
</UL>

<UL>
  <LI><A name="20181011"></A>2018/10/11 Hyperparameter Importance Across Datasets （複数のデータセットを横断して重要な超パラメータの分析）
  <UL>
    <LI> KDD2018勉強会における論文紹介（<a href="KDD2018Reading_Kashima.pdf">スライド</a>）
    <LI> 機械学習手法には多くの超パラメータがあるが、各手法のどの超パラメータが重要かを、
         OpenMLの100個のデータセットを使ってfunctional ANOVAによって調べた研究
    <LI> たとえばRBFカーネルを使ったSVMではカーネル幅や正則化が重要とか、
         ランダムフォレストでは、葉の最小データ数、使用特徴数、ブートストラップが効くとか
    <LI> これまで皆がなんとなく思っていた「民間伝承」を定量的に検証した点が面白い
  </UL>    
</UL>      
      
<UL>
  <LI><A name="20180314"></A>2018/03/14 機械教示（Machine Teaching）
  <UL>
    <LI> 「<a href="https://arxiv.org/pdf/1801.05927.pdf">An Overview of Machine Teaching (arXiv)</a>」：<a href="http://teaching-machines.cc/nips2017/">NIPS 2017でワークショップ</a>（※）が開催されるなど、ちょっとした盛り上がり（初出は90年代だったりする）の機械教示（Machine Teaching; MT）を俯瞰できるサーベイ論文。
    <LI> MT問題とは、普通の機械学習問題よりも一段抽象的な「ある学習アルゴリズムがある解に到達するような訓練データセットを決める」という問題（逆強化学習に近い）。イメージとしては、学生がいて、その学生にある概念（たとえば微分・積分）をマスターさせたいとする。このとき、どの練習問題を解かせればその学生がその概念をマスターできるかという（最小の練習問題集合を）決める問題。ここでの「学生」は、機械学習アルゴリズムである場合もあるし、実際に人間だったりする場合もある。それぞれの場合に対応した問題（以下で具体例を紹介） が考えられるので、そういう意味ではMT問題はいくつかの問題を内包する少し抽象的な問題といえる。
    <LI> たとえば、前述の「学生」＝機械学習アルゴリズムである場合を考えてみると、これは最近話題の、悪意ある第三者が機械学習を攻撃する問題として考えることができる。猫を識別する（既に学習済みの）識別器に対して、（人間には）ほとんど猫に見えるんだけど、一部だけ改ざんした画像を見せて、犬だと誤答させるようにするようなデモンストレーションを見たことがあるかもしれないが、MT問題はこれのもう一段上を行っていて、学習済みの識別器を攻撃するのではなく、学習アルゴリズムの学習過程に介入する攻撃を考えます。つまり、学習データを改ざんすることで、攻撃者の意図する方向に学習させるという攻撃を行う。
    <LI> あるいは、学生＝人間の場合には、まさに、冒頭のイメージで述べたような、いわゆるITS(Intelligent Tutoring System)で扱うような、人間の学習を効率化する教育の問題も含んでいる。
  </UL>    
</UL>
   
<UL>
  <LI><A name="20180301"></A>2018/03/01 ネットワーク埋め込み学習（某所に寄稿した紹介記事）
  <UL>
    <LI> グラフつながりで最近のネットワーク分析の最近の動向をまとめたサーベイ・チュートリアル論文：<BR>
    William L. Hamilton, Rex Ying, Jure Leskovec.<BR>
    Representation Learning on Graphs: Methods and Applications.<BR>
    arXiv:1709.05584, 2018. (to appear in the IEEE Data Engineering Bulletin)<BR>
    を紹介します。最近、似たようなサーベイ論文がいくつか出ていますが、その中では一番よくまとまったものではないかと思います。
    <LI> ネットワークの表現学習ということで、要するに、ソーシャルネットワークのようなネットワーク構造が与えられたときに、それぞれの頂点に対して、「良い」ベクトル表現をつくることが目標です。
    そのベクトル表現を使って、頂点のクラスタリングやクラス分類、リンク予測などに利用できます。
    <LI> この論文では、単に様々な手法を並べただけではなく、これらを「符号化・復号化（エンコーダ・デコーダ）」という観点でまとめて見せている点が、他のサーベイにはない統一的な見方を与えていると思います。
    <LI> 符号化・復号化とは、ネットワークの各頂点を何らかの方法でベクトルで表現（符号化）したとして、逆にこれらから、もとのネットワーク構造を復元（復号か）できるとすると、そのベクトル表現は（もとのネットワークの    構造情報を保ったままネットワークを圧縮できているという点で） 「良い」表現であろうという考え方に基づいています。
    <LI> たとえば、各頂点の隣接関係（リンクで結合されている２頂点という関係）を保存するように符号化するには、隣接関係にある頂点には（主にユークリッド空間において）近いベクトル表現になっているようにすればよいという考え方です。一方で、近いベクトル表現の頂点同志からリンクでつなげていく（復号）ことで、もとのネットワークが復元できることが期待できます。このような考え方に基づく最近よく名前が知られているものとしては DeepWalk, node2vec, LINE などがあります。
    <LI> この考え方を少し広げると、今度は、各頂点の隣接頂点集合（リンクで結合された他の頂点集合）を保存するように符号化するということが考えられます。つまり、隣接関係にある頂点集合が似ている頂点には（言い換えれば「友達の友達」関係の度合いが強いほど）近いベクトル表現になっているようにすればよいという考え方です。
    <LI> この考え方を突き詰めると、それぞれの頂点が、その近接頂点のベクトル表現を使って、再帰的に自分のベクトル表現を定義することで、周辺構造がベクトル表現の中に取り込まれていくという（前回紹介した）「グラフ畳み込み」に近くなっていきます。
  </UL>
</UL>

<UL>
  <LI><A name="20180218"></A>2018/02/18 グラフ深層学習（某所に寄稿した紹介記事）
  <UL>
    <LI> 「【グラフ構造データ：化合物やSNSなどに表現に適したデータ構造】
    グラフとは、頂点の集合が辺で結ばれたデータ構造です。たとえば薬剤（化合物）は、原子（＝頂点）が共有結合（＝辺）で結ばれたグラフ構造を、あるいはSNSなどのネットワークも、人（＝頂点）が友人関係（＝辺）で結ばれたグラフ構造をもっています。このようなデータを分析することで、たとえば「ある化合物が薬としての機能を持ちうるか？」とか「ある2人の間には友人関係が成り立つか？」といった予測が可能になります。他にも、化合物や人を商品や行動などに、その間の関係を購買関係や時間的前後関係などにと置き換えてみることで様々な予測・推薦システムの可能性が考えられます。
    <LI> 【課題：グラフの構造を如何に捉えてベクトル表現するか？】
    では、グラフ構造データといったときに、通常のデータ形式の（いわゆるExcel形式の） 分析と比較して、一体何が難しいのでしょうか。通常の（Excel形式の） データ形式では、各データが「ベクトル」（要するにExcelの「１行」）として表現されます。そして、現在ある機械学習の手法の殆どは、このベクトル表現されたデータを前提としています。一方で、グラフに対するベクトル表現（つまり、グラフをどうやってExcelの1行で表すか？） は自明ではなく、ここがグラフデータ構造データを扱うときの最大の課題になります。
    <LI> 【これまでのアプローチ：柔軟性や表現力に課題】
    グラフ構造のベクトル化については、約20年間にわたって（鹿島を含む）研究者によって取り組まれてきました。初期のものは、データマイニングの分野で用いられる頻出パターンと呼ばれる、データ中に頻繁に表れる部分グラフ構造を発見して、これを特徴としてベクトル化するというアプローチでした。技術的には、データマイニングの世界で培われた離散的な数え上げを基本としています。明示的に部分グラフ構造を取り出すため解釈性が高い反面、（基本的には離散的なデータを対象としたものなので） 数値をともなうグラフや（そもそも計算量的に厳しい問題を扱っていることから）巨大なグラフに対して弱いといった問題があります。
    次に出てきたのが、サポートベクトルマシンなどのカーネル法で、これも一定の部分構造を全て使ってベクトル化するというアプローチです。カーネル法の強みは、統計的学習理論と凸最適化理論に裏打ちされた強力な理論的枠組みであり、これによって属人性の低い「誰がやっても、そこそこ動く」という便利さがあります。一方で、理論的保証のための制約により、グラフの場合は部分構造のクラスを制限することで、時として表現力が足りないという問題が生じます。そのため、計算量を抑えながら表現力を上げることを目指した研究が進められてきました。
    <LI> 【最近の動向：グラフ畳み込みニューラルネットワークによる表現獲得】
   これまでの研究の流れの延長上にあり、近年の深層ニューラルネットワークの隆盛とともに増えているのが、グラフ構造データへのニューラルネットワークによるアプローチです。多くの論文で「グラフ畳み込み（graph convolution）（文献１）」もしくは「メッセージ伝播（message passing）（文献２） 」やこれに類する表現獲得法が用いられています。グラフ畳み込みでは、グラフの各頂点について、その表現ベクトルはその頂点の周辺構造を反映するように学習されます。具体的には、ある頂点を表現するベクトルは、その頂点につながっている他の頂点（たち）を表現するベクトル（たち）によって再帰的に定義され、その再帰式もニューラルネットワークのパラメータとしてデータから学習されます。これによって、カーネル法よりも複雑で、グラフマイニングよりもソフトな部分構造を捉え、それが表現ベクトルとして抽出されます。（ちなみに、このグラフ畳み込みの再帰的な計算過程は、カーネル法のそれと非常によく似ています。）
   グラフニューラルネットワークは、これまでの方法と比較して高精度であるという事例が報告されており、改めて期待が高まっています。ただ、画像に対するCNNほどのジャンプがあるかはまだ未知数であり、そこも含めて検証していく段階といえます。
  </UL>
  <OL>
  <LI> David K. Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alan Aspuru-Guzik, and Ryan P. Adams.<BR>
   Convolutional networks on graphs for learning molecular fingerprints.<BR>
   In Advances in Neural Information Processing Systems (NIPS). 2015.<BR>
   化合物を対象としたグラフ畳み込みニューラルネットワークの定番的論文
  <LI> Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E. Dahl.<BR>
  Neural message passing for quantum chemistry.<BR>
  In Proceedings of the 34th International Conference on Machine Learning (ICML), 2017.<BR>
  Duvenaud et al. （文献１）をはじめ、最近の様々なグラフニューラルネットワークをメッセージ伝播の観点から一般化した論文
   </OL>
</UL>

<!--
<UL>
  <LI><A name="YYYYMMDD"></A>YYYY/MM/DD TITLE
  <UL>
    <LI> CONTENT
    <LI> CONTENT
    <LI> CONTENT
  </UL>    
</UL>
-->

<hr>
</body>
</html>
