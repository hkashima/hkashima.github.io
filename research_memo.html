<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=Shift_JIS">
<meta http-equiv="Content-Style-Type" content="text/css">
<title>研究メモ</title>
</head>
<body>
<p><font size="+2"><b>（か）研究日記</b></font></p>
<hr>
<p> 研究に関連する事柄についてのメモなど。
  必ずしも時系列順に追加されるわけではないよ。
  内容はその日付時点における認識だよ。</p>
<p> <a href="index.html">もどる</a> 
<hr>

<UL>
  <LI><A name="20190725"></A>2019/07/25 Kervolutional Neural Networks （カーネリ込みニューラルネットによる畳み込み操作の非線形化）
  <UL>
    <LI> ExaWizards主催のCVPR2019勉強会における論文紹介（<a href="CVPR2019Reading_Kashima.pdf">スライド</a>）
    <LI> CNNにおける畳み込み操作（線形）をカーネルで非線形化しようというもの。
    <LI> いわゆるカーネル化よりは弱いけど、「Kervolution（カーネリ込み）」の出オチ一発芸が好み。
  </UL>    
</UL>

<UL>
  <LI><A name="20190307"></A>2019/03/07 Human-in-the-Loop Feature Selection (特徴量選択を教師付き学習する)
  <UL>
    <LI> ExaWizards主催のAAAI2019勉強会における論文紹介（<a href="AAAI2019Reading_Kashima.pdf">スライド</a>）
    <LI> 訓練データにおいて、どの特徴が重要かという補助情報（たとえば専門家の注釈など）が与えられている状況を考え、
         これを使って特徴選択器も（教師付き）学習しようというアイディア。
    <LI> 説明可能性の文脈で同じような設定を考えていた（が我々は上手くいかなかった）ので、見事にやられた。素晴らしい。
  </UL>    
</UL>

<UL>
  <LI><A name="20180314"></A>2018/03/14 機械教示（Machine Teaching）
  <UL>
    <LI> 「<a href="https://arxiv.org/pdf/1801.05927.pdf">An Overview of Machine Teaching (arXiv)</a>」：<a href="http://teaching-machines.cc/nips2017/">NIPS 2017でワークショップ</a>（※）が開催されるなど、ちょっとした盛り上がり（初出は90年代だったりする）の機械教示（Machine Teaching; MT）を俯瞰できるサーベイ論文。
    <LI> MT問題とは、普通の機械学習問題よりも一段抽象的な「ある学習アルゴリズムがある解に到達するような訓練データセットを決める」という問題（逆強化学習に近い）。イメージとしては、学生がいて、その学生にある概念（たとえば微分・積分）をマスターさせたいとする。このとき、どの練習問題を解かせればその学生がその概念をマスターできるかという（最小の練習問題集合を）決める問題。ここでの「学生」は、機械学習アルゴリズムである場合もあるし、実際に人間だったりする場合もある。それぞれの場合に対応した問題（以下で具体例を紹介） が考えられるので、そういう意味ではMT問題はいくつかの問題を内包する少し抽象的な問題といえる。
    <LI> たとえば、前述学生＝機械学習アルゴリズムの場合を考えてみると、これは最近話題の、悪意ある第三者が機械学習を攻撃する問題として考えることができる。猫を識別する（既に学習済みの）識別器に対して、（人間には）ほとんど猫に見えるんだけど、一部だけ改ざんした画像を見せて、犬だと誤答させるようにするようなデモンストレーションを見たことがあるかもしれないが、MT問題はこれのもう一段上を行っていて、学習済みの識別器を攻撃するのではなく、学習アルゴリズムの学習過程に介入する攻撃を考えます。つまり、学習データを改ざんすることで、攻撃者の意図する方向に学習させるという攻撃を行う。
    <LI> あるいは、学生＝人間の場合には、まさに、冒頭のイメージで述べたような、いわゆるITS(Intelligent Tutoring System)で扱うような、人間の学習を効率化する教育の問題も含んでいる。
  </UL>    
</UL>

<UL>
  <LI><A name="20180218"></A>2018/02/18 グラフ深層学習（某所に寄稿した紹介記事）
  <UL>
    <LI> 「【グラフ構造データ：化合物やSNSなどに表現に適したデータ構造】
グラフとは、頂点の集合が辺で結ばれたデータ構造です。たとえば薬剤（化合物）は、原子（＝頂点）が共有結合（＝辺）で結ばれたグラフ構造を、あるいはSNSなどのネットワークも、人（＝頂点）が友人関係（＝辺）で結ばれたグラフ構造をもっています。このようなデータを分析することで、たとえば「ある化合物が薬としての機能を持ちうるか？」とか「ある2人の間には友人関係が成り立つか？」といった予測が可能になります。他にも、化合物や人を商品や行動などに、その間の関係を購買関係や時間的前後関係などにと置き換えてみることで様々な予測・推薦システムの可能性が考えられます。
    <LI> 【課題：グラフの構造を如何に捉えてベクトル表現するか？】
では、グラフ構造データといったときに、通常のデータ形式の（いわゆるExcel形式の） 分析と比較して、一体何が難しいのでしょうか。通常の（Excel形式の） データ形式では、各データが「ベクトル」（要するにExcelの「１行」）として表現されます。そして、現在ある機械学習の手法の殆どは、このベクトル表現されたデータを前提としています。一方で、グラフに対するベクトル表現（つまり、グラフをどうやってExcelの1行で表すか？） は自明ではなく、ここがグラフデータ構造データを扱うときの最大の課題になります。
    <LI> 【これまでのアプローチ：柔軟性や表現力に課題】
グラフ構造のベクトル化については、約20年間にわたって（鹿島を含む）研究者によって取り組まれてきました。初期のものは、データマイニングの分野で用いられる頻出パターンと呼ばれる、データ中に頻繁に表れる部分グラフ構造を発見して、これを特徴としてベクトル化するというアプローチでした。技術的には、データマイニングの世界で培われた離散的な数え上げを基本としています。明示的に部分グラフ構造を取り出すため解釈性が高い反面、（基本的には離散的なデータを対象としたものなので） 数値をともなうグラフや（そもそも計算量的に厳しい問題を扱っていることから）巨大なグラフに対して弱いといった問題があります。
 次に出てきたのが、サポートベクトルマシンなどのカーネル法で、これも一定の部分構造を全て使ってベクトル化するというアプローチです。カーネル法の強みは、統計的学習理論と凸最適化理論に裏打ちされた強力な理論的枠組みであり、これによって属人性の低い「誰がやっても、そこそこ動く」という便利さがあります。一方で、理論的保証のための制約により、グラフの場合は部分構造のクラスを制限することで、時として表現力が足りないという問題が生じます。そのため、計算量を抑えながら表現力を上げることを目指した研究が進められてきました。
    <LI> 【最近の動向：グラフ畳み込みニューラルネットワークによる表現獲得】
これまでの研究の流れの延長上にあり、近年の深層ニューラルネットワークの隆盛とともに増えているのが、グラフ構造データへのニューラルネットワークによるアプローチです。多くの論文で「グラフ畳み込み（graph convolution）（文献１）」もしくは「メッセージ伝播（message passing）（文献２） 」やこれに類する表現集出法が用いられています。グラフ畳み込みでは、グラフの各頂点について、その表現ベクトルはその頂点の周辺構造を反映するように学習されます。具体的には、ある頂点を表現するベクトルは、その頂点につながっている他の頂点（たち）を表現するベクトル（たち）によって再帰的に定義され、その再帰式もニューラルネットワークのパラメータとしてデータから学習されます。これによって、カーネル法よりも複雑で、グラフマイニングよりもソフトな部分構造を捉え、それが表現ベクトルとして抽出されます。（ちなみに、このグラフ畳み込みの再帰的な計算過程は、カーネル法のそれと非常によく似ています。）
 グラフニューラルネットワークは、これまでの方法と比較して高精度であるという事例が報告されており、改めて期待が高まっています。ただ、画像に対するCNNほどのジャンプがあるかはまだ未知数であり、そこも含めて検証していく段階といえます。
  </UL>
  <OL>
  <LI> David K. Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Alan Aspuru-Guzik, and Ryan P. Adams.<BR>
   Convolutional networks on graphs for learning molecular fingerprints.<BR>
   In Advances in Neural Information Processing Systems (NIPS). 2015.<BR>
   化合物を対象としたグラフ畳み込みニューラルネットワークの定番的論文
  <LI> Justin Gilmer, Samuel S. Schoenholz, Patrick F. Riley, Oriol Vinyals, and George E. Dahl.<BR>
  Neural message passing for quantum chemistry.<BR>
  In Proceedings of the 34th International Conference on Machine Learning (ICML), 2017.<BR>
  Duvenaud et al. （文献１）をはじめ、最近の様々なグラフニューラルネットワークをメッセージ伝播の観点から一般化した論文
   </OL>
</UL>

<!--
<UL>
  <LI><A name="YYYYMMDD"></A>YYYY/MM/DD TITLE
  <UL>
    <LI> CONTENT
    <LI> CONTENT
    <LI> CONTENT
  </UL>    
</UL>
-->

<hr>
</body>
</html>
