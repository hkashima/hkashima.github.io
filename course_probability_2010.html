<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"> 
<html><head><title>平成22年度冬学期 確率数理要論 【測度論的確率論】</title>
<meta http-equiv="Content-Type" content="text/html; charset=Shift_JIS">
<meta content="MSHTML 6.00.6000.17093" name="GENERATOR">
<meta http-equiv="Content-Style-Type" content="text/css"></head>
<body>
<p><font size="+2"><b>確率数理要論【測度論的確率論】<br>
（東京大学 大学院情報理工学系研究科 数理情報学専攻平成22年度 
冬学期講義）<br>
</b></font><br>
担当教員：<a href="http://www.geocities.jp/kashi_pong/">鹿島 
久嗣</a>（東京大学 大学院情報理工学系研究科 数理情報学専攻 <a href="http://www.ibis.t.u-tokyo.ac.jp/%E3%83%95%E3%83%AD%E3%83%B3%E3%83%88%E3%83%9A%E3%83%BC%E3%82%B8">数理第6研究室</a>）<br>
時間：金曜日2限 
(10:15～11:45)<br>
講義室：工学部6号館6X号講義室<br>

<hr>
<!--- <p></p><font size="+2" color="red">10/29 <a href="report1.pdf">レポート課題</a>を出しました。あと、来週は講義やりません</font><br> s--->
<p></p><font color="red" size="+2">期末試験は2月4日の講義の時間内で行います</font><br>

<p></p><strong>【講義の概要</strong>】<br>
測度論を基礎にした確率論を学びます。後半では確率過程論に少し踏み入ります。測度論の知識は仮定せず、基本的なところから解説します。 
<br>
この講義では、だいたい以下のようなトピックをカバーするつもりです： 
<ol>
  <li>確率空間 
  <li>確率変数 
  <li>期待値 
  <li>独立性 
  <li>確率変数の収束 
  <ul>
    <li>大数の法則 
    <li>中心極限定理 </li></ul>
  <li>特性関数 
  <li>条件付き期待値 
  <li>マルチンゲール 
  <li>ブラウン運動 
  <li>伊藤過程 </li></ol>講義の進み具合によっては、すべて（特に後半）はカバーできないかもしれません。 
<br>
<br>
測度論的確率論は、そもそもが形式的で、また、直接応用が見えるわけでもないので、無味乾燥になる感じは否めません。 
特に、測度論を学んだことのない人には、導入のところでいきなり躓きやすいため、それなりの努力を要します。したがって、退屈を乗り越えるモチベーションが必要かもしれません。 
測度論的確率論を学ぶ御利益といえば、測度論をベースに書かれている専門書や論文などを見ても委縮しなくなれるくらいでしょうか…。金融系などの確率過程をよく用いる分野では、測度論的確率論の知識が前提とされているものが多いようです。 
<br>
<br>
<br>
<strong>【教材・参考書】</strong><br>
基本的には、<a href="http://www.stat.t.u-tokyo.ac.jp/lecture/youron/">昨年までの講義ノート</a>に沿って行うことを予定しています。適宜、 
<a href="http://springer.jp/978-4-431-10026-3">シュリーヴ</a> と <a href="http://www.asakura.co.jp/books/isbn/978-4-254-11600-7/">舟木</a> 
で間を埋める感じでいこうと思います。 
<br>
測度論を学んだことのある方には講義ノートで十分であると思いますが、測度論を学んだことのない人には、これだけでは難しい場合が多いでしょう。測度論の必要な部分を補いつつ解説をしてくれる本も併せて読むのがよいでしょう。先生がみた限りでは、例えば、<a href="http://springer.jp/978-4-431-10026-3">シュリーヴ</a> 
の１～２章はオススメです（じっさい先生はこれに救われました）。 
<ul>
  <li><a href="http://www.stat.t.u-tokyo.ac.jp/lecture/youron/">昨年までの講義ノート（駒木先生＋竹村先生）</a>：概ねこの講義ノートにそったトピックで講義をおこないます 

  <li><a href="http://books.google.co.jp/books?id=6XoPpzFw8BEC&amp;lpg=PP1&amp;ots=X8d6sC_Ilv&amp;dq=Probability%3A%20A%20Survey%20of%20the%20Mathematical%20Theory&amp;pg=PP1#v=onepage&amp;q&amp;f=false">Lamperti: 
  Probability, 2nd Edition, Wiley, 1996.</a>：上の講義ノートは、基本的にこの本に基づいているとのこと。 
  <li><a href="http://springer.jp/978-4-431-10026-3">シュリーヴ: ファイナンスのための確率解析II, 
  シュプリンガー・ジャパン, 2008.</a>：１～４章。 ルベーグ積分などの知識がない状態からでも読めます。 
  <li><a href="http://www.asakura.co.jp/books/isbn/978-4-254-11600-7/">舟木: 確率論, 
  朝倉書店, 2004.</a>：細かい証明なども載っています。 
</li></ul><br>
<br>
<strong>【成績評価】</strong><br>
成績の評価は、主に試験とレポートをもとに行います。 
<ul>
  <li>試験： 中間（１２月２４日）と期末（２月頭）の２回 
  <li>レポート：締め切り１２月３日 </li></ul>出席も一応とりますが、あまり重要視しません（従ってチート不要です）。 
<br>
<br>
<strong>【講義日程と内容のダイジェスト】</strong><br>
<u>第１回（１０月８日）</u>：確率空間（σ加法族と確率測度） 
<ul>
  <li>本講義の概要や参考資料、成績評価法を説明しました（上記の内容です）。 
  <li>確率が与えられるべき対象を規定するσ加法族の定義と、そこから得られる性質（積についても閉じていることなど）を紹介しました。 <br>

  <li>確率測度を定義しました。 また、確率測度の満たす性質（測度の単調性、連続性）などを紹介しました。 </li></ul><font size="2">まずは、すべての始まりである確率空間を定義しました。いきなりσ集合族と確率測度などというものが出てきてやる気を削がれる人も多いと思います。「確率論なんて測度論ですよ」などという向きもあるようですし、測度論をどこかでしっかりと学んできた人にはそんなに難しくないでしょうが、そうでない人にははじめは敷居が高いかもしれません。先生もそうでした。なぜσ集合族じゃないといけないのか、など、いろいろ疑問も出るかと思いますが、あまり気にせず「そうじゃないと困るんだろうな」くらいで進んでしまうのがよいでしょう。あまり細かいことは気にせずに「わからないという状態に慣れる」くらいでよいと思います。ただ、これらの定義はすべての基本であり、ある程度は覚えておいたほうが今後のためです。可算加法性などの基本的な定義や、そこから導かれる測度の単調性、連続性などの基本的な性質は今後の証明でも頻繁に用いられるので、押さえておくとよいでしょう。 
</font><br>
<br>
<u>第２回（１０月１５日）</u>：確率空間つづき（実数軸上の確率測度、分布関数）、確率変数 
<ul>
  <li>実数軸上の確率測度としてよく用いられる、ボレル集合族を紹介しました。 
  <li>実数軸上の確率測度を考えるときによく用いられる分布関数を紹介しました。 確率測度と分布関数が対応していることを見ました。 
  <li>確率変数の定義を紹介しました。 </li></ul><font size="2">知らない人は、（実数軸上の）ボレル集合族に戸惑うことと思います。しかし、ここでその厳密な定義にまで遡って思い悩んでしまうのではなく、とりあえず「実数軸上のボレル集合（ボレル集合族の要素）とは区間のことだよ」くらいにしてしまって、そのイメージをもとに期待値の定義の理解に力を注いだほうが有益と思います。分布関数とは、累積分布のようなものです。これはそんなに悩まないでしょう。確率変数は、なんだか面倒そうな定義になっています。まず定義に出てくる{X∈C}とか、X<sup>-1</sup>(C)などといった表記に戸惑うかもしれません。この定義は、ある程度、イメージできるようになっておいたほうがよいです。図で覚えるといい感じです。ぼちぼち、測度論的確率論の作法というか傾向というか、「こいつがどんなことを言いだしそうな奴か」という少し空気が読めてきますね。気になるものの確率がちゃんと定義されている（σ加法族に入っている）というのをやけに気にする奴のようです。 
</font><br>
<br>
<u>第３回（１０月２２日）</u>：期待値 
<ul>
  <li>確率変数の期待値の定義とその簡単な性質を紹介しました。 
  <li>その定義に用いられるルベーグ積分を復習しました。 
  <li>確率変数に対する確率測度は、確率変数が定義されている確率空間の確率測度からつくられることを見ました。また、両者による期待値は一致することを見ました。 

  <li>その一般化として、可測写像で関係づけられた２つの確率空間における期待値が一致するという定理と、その証明に用いられる標準的手続きを紹介しました。 
  </li></ul><font size="2">期待値のイメージ自体は「いわゆる普通の期待値」でよいのですが、非可算無限の標本空間での期待値はルベーグ積分によって定義されるので、学んだことがなければ最低限必要な部分を確認しておく必要があります。例えば<a href="http://springer.jp/978-4-431-10026-3">シュリーヴ</a>には非常にわかりやすい説明が載っています。期待値の定義のところで、よく定義関数というものが出てきますが、今後もよく出てくるので覚えておきましょう。定義関数の期待値をとると確率になったりとかは、定義上当たり前といえばそうなんですが、個人的には結構重要な気がします。後半の、素朴な期待値の計算と確率変数の分布を使った期待値の計算が一致するというのは、これ自体は「まあ、そうだろうねえ」ですが、これ（の一般化バージョン）の証明の手続き（確率変数が定義関数→単関数→非負関数→一般関数の順に証明する）はよく使われる標準的なやり方なので、確認しておくのがよいと思います。 
</font><br>
<br>
<u>第４回（１０月２９日）</u>：確率変数の収束 
<ul>
  <li><a href="report1.pdf">レポート課題</a>を出しました。 
  <li>確率変数の収束のいくつかの異なる定義（概収束、確率収束、α次平均収束、弱収束）を紹介しました。 
  <li>各種収束のあいだの関係（概収束⇒確率収束、α次平均収束⇒確率収束）を証明しました。 
  <li>証明においてよく用いられる単調収束定理とルベーグの収束定理を紹介しました。 </li></ul><font size="2">確率変数の収束には、概収束、確率収束、α次平均収束などいくつかの定義があります。他にも、中心極限定理などに結びつく弱収束という定義もあるのですが、これはまた後の講義で出てくることになります（とびきり面倒ですよ）。とくに、概収束と確率収束の違いは毎回忘れてしまいそうになりますが、確率変数の収束の確率を論じているか（概収束）、確率の収束を論じているか（確率収束）の違いはよく確認しておくのがよいと思います。それぞれに対応するのが大数の強法則と弱法則で、次回あたりで紹介することになると思います。 
<br>
レポート課題を出しました（といっても、問題解くだけですが）。出題範囲は、まだ講義で触れていない範囲にも及んでいるので、課題の締め切りまでには追い付きたいところです…。 
</font><br>
<br>
<u>第５回（１１月１２日）</u>：独立性 
<ul>
  <li>事象の独立性、確率変数の独立性の定義を紹介しました。 
  <li>多変数の確率分布、分布関数、密度関数と、その独立性との関係を紹介しました。 
  <li>独立な複数の確率変数の積の期待値は、それぞれの期待値の積になることを証明しました。 
  <li>独立な複数の確率変数の和の従う分布関数を導きました。 </li></ul><font size="2">コの付くむかしのエライ人によれば、独立性というのは確率論を、測度論の単なる応用ではなく、数学の固有の一分野たらしめているものといっても過言ではないというくらい、極めて重要な概念らしいです。独立性の定義に伴い、複数の確率変数が登場したので、多変数の確率分布の話をしました。密度関数についてもいままで出てきていなかったので、ここで初めて登場したわけですが、分布関数は必ず存在するが、密度関数は必ずしも存在するわけではない、というのは豆知識です（その存在条件には深入りしません）。独立な確率変数XとYに対しE[XY]=E[X]E[Y}が成り立つことの証明は、例の常套手段（定義関数→単関数→非負関数→一般関数）を使います。 
XとYの和の従う確率の式の証明には、2重積分と2回の積分が等価となる条件を与える「フビニの定理」を用います。これはもはや証明というよりは、フビニそのものですね。 
まさにフビニさまさまという感じです。 </font><br>
<br>
<u>第６回（１１月１９日）</u>：大数の弱法則 
<ul>
  <li>大数の弱法則（標本平均の確率収束）と強法則（標本平均の概収束）を紹介しました。 
  <li>弱法則を証明しました。 
  <li>ボレル=カンテリの補題を証明しました。 </li></ul><font size="2">確率収束と概収束の重要な具体例でもある、大数の法則の話です。弱法則の方は、ほとんどチェビシェフ一発なので、難しくないですが、強法則の証明には（簡単バージョンでいくにしても）いろいろと準備が必要です。上極限、下極限の定義は最初見たときには何を言いたいのやらさっぱりわかりませんでした（お金もらってなければ、ここで一回挫折です）。ボレル=カンテリは2番目のほうだけ独立性を仮定しているのに注意です。 
さて、講義中に質問がありましたが、 
2つの確率変数X<sub>1</sub>とX<sub>2</sub>がi.i.d.、つまり、同一の分布に独立に従うといったとき、 
P(|X<sub>1</sub>+X<sub>2</sub>|＜t)のようなものを評価したいとします。これは、厳密には、P({ω; 
|X<sub>1</sub>(ω)+X<sub>2</sub>(ω)|＜t})という意味ですが、質問はたしか、X<sub>1</sub>(ω)とX<sub>2</sub>(ω)が同じωによっているなら、独立もなにもないんじゃないの？ということだったように思います。そういわれるとそんな気がしてきますね。先生、家に帰ってから、定義に戻ってよくよく考えてみると、ポイントは「同一なのは確率変数の分布であって確率変数そのものではない」ということなのだろうという気がしてきました。たとえば、ωを同じコインを2回振って出る結果の組とし、X<sub>1</sub>を1回目の結果が表(1)か裏(0)か、 
X<sub>2</sub>を2回目の結果が表か裏かによって定義すれば、それぞれの確率変数の分布は等しく、また、独立になります。 
</font><br>
<br>
<u>第７回（１１月２６日）</u>：大数の強法則、弱収束の定義 
<ul>
  <li>コルモゴロフの不等式の証明をしました。 
  <li>大数の強法則の証明（分散が有限の場合）を行いました。 
  <li>弱収束の定義を紹介し、その「分布が収束すること」との等価性を証明しました。 </li></ul><font size="2">大数の法則の証明は一般的にやると面倒なので、簡単バージョンとして、分散が有限の場合を示しました。これはコルモゴロフの不等式という、チェビシェフのスゴイ版を使うと、結構簡単に示すことができます。これは、独立確率変数の部分和の最大値を抑える、いかにも役に立ちそうな不等式ですね。次は収束四天王のボス、いやむしろ「ククク…奴は我々収束四天王の中でも最弱…」であるところの弱収束です。どこかで弱収束は「分布の収束」であるときいたことがある人もいるかもしれませんが、「任意の連測有界関数の期待値が収束する」などという定義とは、まったく結び付きませんね…。実はこれらが等価であるということが示されます。じゃあ、初めからこっちで定義しろよ、と言いたくなりますね。まったく。 
</font><br>
<br>
<u>第８回（１２月３日）</u>：弱収束の性質 
<ul>
  <li>確率収束するなら、弱収束することを証明しました。 
  <li>ヘリーの選出定理、プロホロフの定理を紹介しました。 </li></ul><font size="2">これまでにもいろいろな種類の収束とそれらの間の関係をみてきましたが、今回は「確率収束するならば弱収束する」の証明です。いままでは確率収束が最弱だったのですが、弱収束が登場したことで、最下位の座を免れました。さすが弱収束、だてに「弱」を名乗っているわけではありませんな。前回、弱収束と分布関数の収束が等価であることを示しましたが、証明では、後者の分布の収束のほうを使って示します。弱収束に関連した、もうひとつの重要な定理が、「分布関数列から、適当に部分列をとって弱収束するようにできる」というプロホロフの定理です。これの、収束先が分布関数になっているかという保証がないバージョンがヘリーの選出定理で、これに「タイト」という条件が加わると、収束先が分布関数であることがいえます。また、今回の講義ではやりませんでしたが、ヘリーの選出定理の証明は、「対角線論法」という手法をつかったものです。なんか上手いことやっているので、紹介したいような気もしますが、時間の関係でスキップせざるを得ませんでした…。 
</font><br>
<br>
<u>第９回（１２月１０日）</u>：特性関数、中心極限定理 
<ul>
  <li>特性関数の定義と、これが確率測度と一対一に対応すること（レヴィの公式）を紹介しました。 
  <li>連続性定理を証明しました。 
  <li>中心極限定理を証明しました。 
</li></ul><font size="2">講義としては今年最後となってしまいます（２４日は中間試験）が、いろいろ端折りつつも、なんとか今年のうちに中心極限定理までたどり着いたという形です。時間の関係で、泣きながら準備したものをいろいろ省略することになりました、もったいないです…。さて、中心極限定理の証明に必要なもう一つの道具が特性関数です。特性関数は、レヴィの公式によって保証されますが、分布関数と一対一に対応づけられるという重要な性質がありますが、同じく重要なのが弱収束との関係です。分布関数が収束すれば特性関数も収束しますが、その逆は必ずしも成り立たつわけではありません。そして、その条件を与えるのが、（前回やったプロホロフの定理を用いて証明される）連続性定理です。中心極限定理とは弱収束であるので、対象の分布関数の特性関数の列が、正規分布の特性関数へと収束することを示すことによって中心極限定理が示されるという流れです。道程が長すぎて、途中で目的を少なくとも3回は忘れます。</font> 
<br>
<br>
<u>中間試験（１２月２４日）</u>：弱収束の前まで 
<br>
<br>
<br>
<u>第１０回（１月１４日）</u>：条件付き期待値 
<ul>
  <li>条件付き期待値の定義を紹介しました。
  <li>条件付き期待値が一意に存在することを（ラドン-ニコディムの定理を使って）示しました。
  <li>条件付き期待値のいくつかの性質（線形性、独立性など）を紹介しました。</li>
</ul><font size="2">
コメント
</font><br>
<br>
<u>第１１回（１月２８日）</u>：確率過程（フィルトレーション、マルチンゲール、ブラウン運動）と確率積分
<ul>
  <li>時間を伴う確率変数である確率過程と、時間とともに発展するσ加法族であるフィルトレーション（増大情報系）の定義を紹介しました。
  <li>適合確率過程と、その重要なクラスであるマルチンゲールを紹介しました。
  <li>連続するコイン投げの極限としてブラウン運動を紹介しました。
  <li>ブラウン運動で確率過程を積分する確率積分を紹介しました。
</li>
</ul>
</ul><font size="2">
コメント
</font>
<br>
<br>
<u>期末試験（２月４日）</u>：全部</body></html>
